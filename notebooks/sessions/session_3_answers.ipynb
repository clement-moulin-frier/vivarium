{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 3: Parallel behaviors and more sensing abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session, we saw how to define, attach, start, stop and detach a behavior on an agent agent. We implemented three distinct behaviors: `slow_down`, `fear` and `aggression`.\n",
    "\n",
    "In this section we will see more sensing abilities the agent is equipped with, will define new behaviors using them and will see how to deal with multiple behaviors running in parallel on the same agent. At the end of the session, we will also see how to attach those behaviors on multiple agents interacting together within a Vivarium scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, start the server, the interface and open the simulator session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "from vivarium.utils.handle_server_interface import start_server_and_interface, stop_server_and_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cleger/Desktop/code/vivarium/vivarium/utils\n",
      "\n",
      "STARTING SERVER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-10 16:11:59,554][__main__][INFO] - Scene running: session_3\n",
      "[2024-12-10 16:12:02,080][vivarium.simulator.simulator][INFO] - Simulator initialized\n",
      "\n",
      "STARTING INTERFACE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 16:12:04,968 Starting Bokeh server version 3.3.4 (running on Tornado 6.4)\n",
      "2024-12-10 16:12:04,969 User authentication hooks NOT provided (default user enabled)\n",
      "2024-12-10 16:12:04,970 Bokeh app running at: http://localhost:5006/run_interface\n",
      "2024-12-10 16:12:04,970 Starting Bokeh server with process id: 42909\n",
      "2024-12-10 16:12:23,233 An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "2024-12-10 16:12:24,944 WebSocket connection opened\n",
      "2024-12-10 16:12:24,969 ServerConnection created\n"
     ]
    }
   ],
   "source": [
    "start_server_and_interface(scene_name=\"session_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the interface link shows up (http://localhost:5006/run_interface) and click on it, and make sure the scene is present on your browser. You should now only see one agent in the environment. If it is the case, you can ignore this instruction and skip to the next cell.\n",
    "\n",
    "Else, if you see two agents, it means a plotting error happened, and that simulations that shouldn't exist are still displayed. To fix it, open the `SIMULATOR` tab of the interface. Inside this tab, untick the `Hide non existing` checkbox, and tick it again. The scene should now be displayed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a controller that will be used to control the simulation with Python code from this jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cleger/Desktop/code/vivarium/venv/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectively detecting scene objects\n",
    "\n",
    "To define a repertoire of interesting behaviors, we need the agent to selectively sense the proximity of different types of entities around them. For example, we might want to define a behavior for obstacle avoidance and another one for attraction towards mates. The first behavior will require sensors information about objects, whereas the second will require the proximeters to detect other agents (although there is only one agent in the scene for now, we'll add more at the end of this session). \n",
    "\n",
    "Since there is only one agent, let's create an alias variable to access it as in previous sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = controller.agents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the agent turn on itself, and call the `sensors` function with different orientations of the agent to test it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the agent turn on itself\n",
    "agent.left_motor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure the following cell gives different values each time you call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6210706233978271 0.43645232915878296\n"
     ]
    }
   ],
   "source": [
    "left, right = agent.sensors()\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in interface, there are three types of entity in the current scene: a blue circle and a number of orange and green squares. By default in Vivarium, circle entites represent agents and square entities represent objects. Here we have two subtypes of objects: large orange ones and smaller green ones. In this sessions, we call the orange objects \"obstacles\" and the green objects \"resources\". \n",
    "\n",
    "We can print the names of the existing subtypes in the scene with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obstacles', 'agents', 'resources']\n"
     ]
    }
   ],
   "source": [
    "controller.print_subtypes_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for informaiton, the types (agent or objects), subtypes (agents, obstacles or resources) and their respective colors are defined in a scene configuration file. The configuration file of the current scene is located at [conf/scene/session_3.yaml](../../conf/scene/session_3.yaml). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the result returned by the agent's proximeters by providing the argument `sensed_entities` to the `sensors` function. Let's detect only one type of entities (e.g obstacles). It should only return positive values when the proximeters are sensing the obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045309484004974365 0.4463422894477844\n"
     ]
    }
   ],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"obstacles\"])\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the cell above will return the proximeter activations only for the `obstacles` entities (the orange squares in the scene). Give it a try by first stopping the agent wheels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop_motors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then move an obstacle in the detection area of the proximiters and re-executing the cell above that calls `agent.sensor(.)` to observe the change in the returned values. You can also check that the proximeter activations are not modified by other objects such as ressources (little green squares).\n",
    "\n",
    "Note that selective sensive can be occluded by other entities, whatever their subtype. This mean that if e.g. a `resource` object is closer than any `obstacle` object in the proximiter field of view, then `agent.sensors(sensed_entities=[\"obstacles\"])` will return `0` for that proximiter. This is somehow similar to how our own eyes sense objects: if you look at a tree but there is a wall between the tree and yourself, you won't see that tree. \n",
    "\n",
    "The `sensed_entities` argument requires a list of strings (`[\"obstacles\"]` in the example above). In Python, a list is a collection of values separated by commas and surrounded by square bracket: `[\"obstacles\"]` is therefore a list of only one element (the string `\"obstacles\"`), whereas `[\"obstacles\", \"agents\"]` is a list of two elements (the strings `\"obstacles\"` and `\"agents\"`). \n",
    "\n",
    "The `sensed_entities` argument, as its name indicates, specifies the entities to be sensed by the proximeters. You can get the subtype of any entity in the scene by using the `print_infos` function, and looking at the `Subtype` field. For example, select the object with index `0`in the interface (you can do this by clicking on `0` in the `Selection` list of the `OBJECT` column on the interface). You check the subtype of the object with index `0` with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Overview:\n",
      "--------------------\n",
      "Type: OBJECT\n",
      "Subtype: resources\n",
      "Idx: 2\n",
      "Exists: True\n",
      "Position: x=166.38, y=93.69\n",
      "Diameter: 5.00\n",
      "Color: #008000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "object_idx = 0  # index of the object of interest\n",
    "object = controller.objects[object_idx]  # get the object of interest\n",
    "object.print_infos()  # print the object's information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the object you selected in the interface was a green square (resp. an orange square), the subtyte printed above should `resources` (resp. obstacle). Alternatively you can also look at the value of the `Subtype` field at the bottom of the `OBJECT` column in the interface. Here the subtype is encoded as an integer, which correspond to the order in which subtypes are defined in the scene configuration file (the yaml file mentioned above), starting at `0`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the same for the agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Overview:\n",
      "--------------------\n",
      "Type: AGENT\n",
      "Subtype: agents\n",
      "Idx: 0\n",
      "Exists: True\n",
      "Position: x=67.03, y=62.24\n",
      "Diameter: 10.00\n",
      "Color: #0000ff\n",
      "\n",
      "Sensors: Left=0.16, Right=0.48\n",
      "Motors: Left=0.00, Right=0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_infos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent's sensor can also detect multiple subtypes of entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16129142045974731 0.4757142663002014\n"
     ]
    }
   ],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"resources\", \"obstacles\"])\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case it will sense the closest entities that are of one of the indicated subtype (i.e. here the closest entities which are either resources or obstacles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives an error message if you provide a string that doesn't correspond to an existing subtype or that is spelled wrong, and ask you to select a type among the correct ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please specify valid sensed entities among {'resources', 'agents', 'obstacles'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m left, right \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensed_entities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresssources\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# typo in the entity subtype\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/code/vivarium/vivarium/controllers/notebook_controller.py:150\u001b[0m, in \u001b[0;36mAgent.sensors\u001b[0;34m(self, sensed_entities)\u001b[0m\n\u001b[1;32m    147\u001b[0m left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mleft_prox, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mright_prox\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sensed_entities \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# transform the strings of sensed entities into ints (this fn can surely be optimized)\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    151\u001b[0m         ent_subtype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_subtypes \u001b[38;5;28;01mfor\u001b[39;00m ent_subtype \u001b[38;5;129;01min\u001b[39;00m sensed_entities\n\u001b[1;32m    152\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease specify valid sensed entities among \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_subtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m     sensed_entities \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subtype_label_to_idx[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m sensed_entities\n\u001b[1;32m    155\u001b[0m     ]\n\u001b[1;32m    156\u001b[0m     sensed_type_left, sensed_type_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprox_sensed_ent_type\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please specify valid sensed entities among {'resources', 'agents', 'obstacles'}"
     ]
    }
   ],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"resssources\"])  # typo in the entity subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** Write the code printing the proximeter activations for resources and test that it works as expected by placing your agent close to those objects and verifying the returned values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Define an `obstacle_avoidance` behavior. The agent has to turn in the direction opposite to the obstacles it detects, with its speed inversely proportional to the proximeter activations (the closer an obstacle, the lower the speed). \n",
    "*Tip:* it is similar to the `shyness` behavior of [Braitenberg vehicles](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoidance(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"obstacles\"])\n",
    "    return 1. - right, 1. - left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that to test a behavior, you first have to detach all behaviors that could still be attached to the agent, then to attach the new one, that is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()\n",
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent should now smoothly navigate between the obstacles in the scene. You can now detach this behavior and stop its motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors(stop_motors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, the environment in which the agent is evolving was quite static: although some objects can be pushed by the agent (e.g. the obstacles or the resources), there is nothing that appears or disappears in the environment. We are now going to see how we can generate food sources appearing at random positions in the environment and disappearing whenever a agent eats them. A food source is modeled as a `resources` object (the green squares). Before making these resources spawn, we need to do a few things before implementing a mechanism where the agent will eat ressources :\n",
    "\n",
    "- Add `resources` to the agent's diets\n",
    "- Start the eating mechanism with the controller\n",
    "- Start the apparition of `resources` with the controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the diet of agents\n",
    "\n",
    "First, let's handle the diet of the agent, we can check his current diet and eating range with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent eating information:\n",
      "Current agent diet: []\n",
      "Current agent eating range: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAgent eating information:\")\n",
    "print(f\"Current agent diet: {agent.diet}\")\n",
    "print(f\"Current agent eating range: {agent.eating_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diet of the agent is a list of entity subtypes the agent can it. As we see above the list is currently empty, which means that our agent is not able to eat anything. \n",
    "\n",
    "The default eating mechanism in Vivarium is pretty basic: an agent will eat an entity whose subtype is in its diet whenever that entity is at a distance lesser than the specified eating range. As seen above, the current eating range is 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get theses informations by using the print_infos() function, with `full_infos` set to True (but it will also print a lot of other informations you might not be interested in): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Overview:\n",
      "--------------------\n",
      "Type: AGENT\n",
      "Subtype: agents\n",
      "Idx: 0\n",
      "Exists: True\n",
      "Position: x=168.39, y=52.94\n",
      "Diameter: 10.00\n",
      "Color: #0000ff\n",
      "\n",
      "Sensors: Left=0.18, Right=0.14\n",
      "Motors: Left=0.86, Right=0.82\n",
      "\n",
      "Diet: []\n",
      "Eating range: 10\n",
      "\n",
      "Configuration Details:\n",
      "  - exists: True\n",
      "  - friction: 0.10000000149011612\n",
      "  - idx: 0\n",
      "  - left_prox: 0.1849607229232788\n",
      "  - mass_center: 1.0\n",
      "  - mass_orientation: 0.125\n",
      "  - max_speed: 10.0\n",
      "  - orientation: -20.157814025878906\n",
      "  - prox_sensed_ent_idx: [14 25]\n",
      "  - prox_sensed_ent_type: [2 2]\n",
      "  - proximity_map_dist: [  0.         122.75478363  40.76202393  53.77086639  88.56233978\n",
      "  95.79457092  86.38492584  97.28276062 124.18735504  84.50136566\n",
      "  81.22528839  92.90860748  95.36893463  77.94844055  48.90235519\n",
      "  89.24980927 134.86087036  49.07868958 104.60174561  73.69913483\n",
      " 107.42179871  94.05405426  63.26244736  74.66112518  74.76796722\n",
      "  51.5250473   91.29888153  79.05609131 124.00660706]\n",
      "  - proximity_map_theta: [ 0.         22.5254879  21.77760124 18.1243782  17.11683083 20.35341835\n",
      " 22.99061584 17.91903114 22.5437336  22.07439804 20.37530518 22.12435722\n",
      " 19.24012566 21.8033886  20.30655289 23.08527756 17.80094719 19.94161224\n",
      " 22.44849396 17.44564629 22.10814285 17.83309174 20.75712013 22.35065842\n",
      " 22.06754875 18.6065464  19.31732559 20.52625084 22.47415543]\n",
      "  - proxs_cos_min: 0.0\n",
      "  - proxs_dist_max: 60.0\n",
      "  - right_prox: 0.14124923944473267\n",
      "  - speed_mul: 1.0\n",
      "  - subtype: 0\n",
      "  - theta_mul: 1.0\n",
      "  - wheel_diameter: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agent.print_infos(full_infos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then manually add ressources to the agent's diet, by setting it in a list of strings, as for the `sensed_entities` argument of the `sensors` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.diet = [\"resources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if the eating mechanism is started, the agents will eat the resources that are at its eating range. If we wanted them to eat other kind of entities such as obstacles, we would have to add `obstacles` to the diet of the agents (make sure to use ortographthe entities subtypes correctly, by using the `controller.print_subtypes_list()` function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the eating mechanism\n",
    "\n",
    "You can then easily start the eating of the controller mechanism with the command in the following cell. This will make the agents eat the resources in their diet and eating range. You also have an option to only eat the resources in your proximeters range ... don't know if it is useful to tell it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_eating_mechanism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever the agent is touching a resource it will \"eat\" it, meaning that the resource will disappear from the environment. You can see it by manually moving the agent close to a resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start spawning of resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to make this scene more interesting, we can start ressources apparition ! To do so, we need to specify an interval of steps between each apparition of a resource with the `interval` parameter. To get a good approximation of this interval, use the get fps function to know how many steps per seconds are done in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measuring the FPS (number of steps per second) in the controller during 2 seconds ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.50\n"
     ]
    }
   ],
   "source": [
    "controller.print_fps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. if we want a resource to appear every 2 seconds, we will set the interval to 2 * FPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# replace by your actual fps value\n",
    "fps = 30\n",
    "seconds = 2\n",
    "interval = seconds * fps\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, start the spawning of resources with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_resources_apparition(interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()\n",
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resources should now appear at random positions in the scene. This will be done until the maximum number of resources is reached in the environment (it is set to 12 for this session). If this is the case and the agent eats a resource somewhere, another one will appear at a random position in the scene.\n",
    "\n",
    "You can also stop the spawning of resources with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop_resources_apparition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to, you can also remove all the entities of a certain type with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.remove_entity_type(\"resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the resources apparition function is still attached to the controller, it will keep spawning resources even after removing them with the precedent function. It will print an information message for all the non existing entities of this type we tried to remove (here, already non-existing ressources)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom position of resources spawning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also control the position range where the resources will appear with the `position_range` parameter. This parameter is a list of 4 values: ((x_min, x_max), (y_min, y_max)) where x_min and x_max are the minimum and maximum x coordinates of the spawning area, and y_min and y_max are the minimum and maximum y coordinates of the spawning area. For example, to make resources appear only in the area between x=0 and x=50, and y=100 and y=200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, start the spawning apparition in a specific area\n",
    "controller.start_resources_apparition(interval=interval, position_range=((0, 50), (100, 200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above will generate resources at random 2D positions $(x, y)$ in the scene with $x\\in[0, 50]$, $y\\in[100, 200]$ (analyze the cell above to understand how the `position_range` argument is converted in $(x, y)$ intervals and ask us if it is not clear). You can easiely check the coordinate of an entity in the web interface.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENT: Update the question "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD **Q3:** Write the code that makes resource appearing just above one of the trees and so that they then roll in various directions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Write the code that removes the resources from the environment, and make them appear in the bottom-right corner of the scene (approximately the quarter of the environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entity 3 already removed\n",
      "Entity 13 already removed\n"
     ]
    }
   ],
   "source": [
    "controller.stop_resources_apparition()\n",
    "controller.remove_entity_type(\"resources\")\n",
    "controller.start_resources_apparition(interval=interval, position_range=((100, 200), (0, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this mechanism a bit, and then stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop_resources_apparition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Define a behavior allowing the agent to catch food sources, let's call it `foraging`. The agent has to orient itself toward food sources, with a speed proportional to the proximiter activations (the closer the food source, the higher the speed) \n",
    "\n",
    "- *Tip 1:* It's similar to the `aggression` behavior. \n",
    "- *Tip 2:* You already saw how to detect `obstacles` in the obstacle avoidance behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"resources\"])\n",
    "    return right, left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach and start the behavior on the agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First detach previous behaviors that might still be attached to the agent\n",
    "agent.detach_all_behaviors()\n",
    "\n",
    "# Write the code to attach and start the `foraging` behavior below\n",
    "agent.attach_behavior(foraging)\n",
    "agent.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached behaviors: ['foraging'], Started behaviors: ['foraging']\n"
     ]
    }
   ],
   "source": [
    "agent.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a resource is detected by the proximeters, the agent should go towards it. However, if at one point the proximeters don't detect any resource, the agent will probably stop (depending on how you have defined the behavior). The only event that could make the agent move again would be a resource that spawns within the proximeter detection area, which is not very likely to happen (and therefore quite a bad option if the survival of the agent depends on its foraging abilities). \n",
    "\n",
    "A solution to avoid such a blocking situation is to combine the `foraging` behavior with another one that keeps the agent in movement, as it is for example the case of the `obstacle_avoidance` behavior we have defined before. Let's attach and start the `obstacle_avoidance` behavior, but this time without detaching the previously attached `foraging` behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we haven't detached the previous behavior, the agent is now executing two behaviors in parallel. This can be checked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached behaviors: ['foraging', 'obstacle_avoidance'], Started behaviors: ['foraging', 'obstacle_avoidance']\n"
     ]
    }
   ],
   "source": [
    "agent.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which tells us that both behaviors are attached and started. In V-REP, you can see that the agent is now both foraging and avoiding obstacles. For doing so, the motor activation sent to each wheel corresponds to the average of the motor activation returned by each behavior (this averaging is implemented internally, you don't need to worry about it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with multiple agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explains how to deal with multiple agents and how to attach different behaviors to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment there is only 1 existing agent that we can see in the scene. But there is actually another one that is not existing yet. We can print it with the `controller.agents`. It is a list with two agents inside. As we accessed the first agent with `agents[0]` before (because it is the first element of the list), we can access the second agent with `agents[1]` (because it is the second ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "agents = controller.agents\n",
    "# print the number of agents in the simulation\n",
    "print(len(agents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rename our original `agent` to `agent_0` and the new one to `agent_1` to make things clearer. The agent 0 still exactly has the same characteristics as before, you can see it moving the same in the interface, and also check he still has the same behaviors attached to him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0 = controller.agents[0]\n",
    "agent_1 = controller.agents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached behaviors: ['foraging', 'obstacle_avoidance'], Started behaviors: ['foraging', 'obstacle_avoidance']\n"
     ]
    }
   ],
   "source": [
    "agent_0.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the second one spawn by setting its `exists` flag to `True` instead of `False` (this mechanism is further explained in the 5th session, don't worry too much about it at the moment and simply execute the next cell). We will also set the second agent to be red, so that we can differentiate it from the first one, and also add the 'resources' to its diet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all agents spawn with the exists flag\n",
    "agent_1.exists = True\n",
    "agent_1.color = 'red'\n",
    "agent_1.diet = [\"resources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have access to the two agents through the variables `agent_0` and `agent_1` (these variables names are arbitrary, you can choose whatever you want, e.g. `predator` and `prey`). You can attach and start behaviors on each agent independently, in the same way as you did before, simply using either the `agent_0` and `agent_1` variables instead of only `agent` one as before.\n",
    "\n",
    "As an example, let's say we want to attach the `obstacle_avoidance` behavior we have defined above to `agent_0`, and both the `obstacle_avoidance` and the `foraging` behaviors to `agent_1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent_0 behaviors:\n",
      "Attached behaviors: ['obstacle_avoidance'], Started behaviors: ['obstacle_avoidance']\n",
      "\n",
      "Agent_1 behaviors:\n",
      "Attached behaviors: ['obstacle_avoidance', 'foraging'], Started behaviors: ['obstacle_avoidance', 'foraging']\n"
     ]
    }
   ],
   "source": [
    "# detach the agent_0 behaviors and only attach the obstacle_avoidance behavior\n",
    "agent_0.detach_all_behaviors()\n",
    "agent_0.attach_behavior(obstacle_avoidance)\n",
    "print(\"\\nAgent_0 behaviors:\")\n",
    "agent_0.print_behaviors()\n",
    "\n",
    "# attach the obstacle_avoidance and foraging behaviors to agent_1\n",
    "agent_1.attach_behavior(obstacle_avoidance)\n",
    "agent_1.attach_behavior(foraging)\n",
    "print(\"\\nAgent_1 behaviors:\")\n",
    "agent_1.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the resources apparition mechanism again to see if `agent_1` is able to catch the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_resources_apparition(interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Implement the `fear` and `aggression` behaviors so that they are directed only toward the other agent, using the `tracked_objects` argument of the `prox_activations` function as we have seen above. Then attach both the `obstacle_avoidance` and the `aggression` behaviors to one agent, and both the `obstacle_avoidance` and the `fear` behaviors on the second. If you did it well, you should observe a simple \"prey-predator\" interaction, where `agent_0` tries to catch `agent_1` and `agent_1` tries to escape from `agent_0`.\n",
    "\n",
    "First, you can detach the behaviors and stop the motors of both agents with the following cell. Using this `for` loop on the `controller.agents` and the `detach_behaviors` function enables you to detach the behaviors of all the agents at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute functions on all agents at the same time\n",
    "for ag in controller.agents:\n",
    "    ag.detach_all_behaviors(stop_motors=True)\n",
    "\n",
    "# In this case because there are only two agents, equivalent to:\n",
    "agent_0.detach_all_behaviors(stop_motors=True)\n",
    "agent_1.detach_all_behaviors(stop_motors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `fear` and `aggression` behaviors towards other agents in the cell below.\n",
    "\n",
    "- *Tip 1:* You already saw how to define `aggression` behavior toward every entity. \n",
    "- *Tip 2:* You now want to fear and agress other agents, you might want to specificaly sense them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggression(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"agents\"])\n",
    "    return right, left\n",
    "\n",
    "def fear(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"agents\"])\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the aggression and obstacle_avoidance behaviors to agent_0, and increase its diameter\n",
    "agent_0.attach_behavior(aggression)\n",
    "agent_0.attach_behavior(obstacle_avoidance)\n",
    "agent_0.start_all_behaviors()\n",
    "agent_0.diameter = 10.\n",
    "agent_0.color = 'red'\n",
    "agent_0.wheel_diameter = 2.5\n",
    "\n",
    "# attach the fear and obstacle_avoidance behaviors to agent_1, decrease its diameter, and increase its speed\n",
    "agent_1.attach_behavior(fear)\n",
    "agent_1.attach_behavior(obstacle_avoidance)\n",
    "agent_1.start_all_behaviors()\n",
    "agent_1.diameter = 4.\n",
    "agent_1.color = 'cyan'\n",
    "agent_1.wheel_diameter = 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent sensors\n",
    "\n",
    "You should observe that the `agent_0` will try to chase the `agent_1` when it detects it, and that the `agent_1` is avoiding `agent_0`. They should be both avoiding obstacles as well. But because the sensors of `agent_1` are only directed in the forward direction, it is really hard to avoid the `agent_0` when it get behind him because cannot see it. Additionally, the `agent_0` is a predator but has a pretty bad vision because it can't see very far.\n",
    "\n",
    "We can fix this by modifying the sensors characteristics of the agents, by changing their angles and max ranges by using the following cell. The `prox_dist_max` parameter is the maximum distance at which the sensors can detect entities, and the `prox_cos_min` parameter is the minimum cosine of the angle between the sensor and the entity for the sensor to detect it. So the `prox_cos_min` value is between -1 and 1. The closer this value is to 1, the narrower the sensor field of view, and inversely for -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the range of the big agent and decrease its angle\n",
    "agent_0.proxs_dist_max = 100.\n",
    "agent_0.proxs_cos_min = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the range of the small agent and increase its angle\n",
    "agent_1.proxs_dist_max = 40.\n",
    "agent_1.proxs_cos_min = -0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the advantages of having a better vision for the predator agent ? For the prey agent ? What would be the optimal parameters for both if you had to choose a trade-off between (e.g because increasing range / angle of sensors would cost more energy for an agent) the max range and the angle of the sensors in your opinion ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Found the process scripts/run_interface.py running with this PID: 42909\n",
      " Found the process scripts/run_server.py running with this PID: 42670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulator is already stopped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping server and interface processes\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Killed process with PID: 42909\n",
      "Killed process with PID: 42670\n",
      "\n",
      "Server and Interface processes have been stopped\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received signal 15, shutting down\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller.stop()\n",
    "stop_server_and_interface(safe_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you finished session 3, you can now jump to the notebook of [session 4](session_4.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
