{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 4: Modulating internal states and Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session, we saw how to run multiple behaviors in parallel on multiple robots. In this section we will see more advanced methods for combining behaviors by modulating their activations according to internal states of the robot and by allowing them to sense the attributes of others. In order to start with a clean basis, let's first provide the definition of several behaviors. These four behaviors are simply implementations of the [Braitenberg vehicles](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0) we have seen in class, where the sources (i.e. what is sensed by the proximeters) are other robots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment \n",
    "\n",
    "- Make sure to untick and tick back the `hiden non existing` button in the simulator interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fear(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"robots\"])\n",
    "    left_wheel = left\n",
    "    right_wheel = right\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def aggression(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"robots\"])\n",
    "    left_wheel = right\n",
    "    right_wheel = left\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_cuddly(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"robots\"])\n",
    "    left_wheel = 1 - left\n",
    "    right_wheel = 1 - right   \n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_shy(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"robots\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the arguments of the behavior functions above are now named `robot`, whereas they were named `robot`in the previous sessions. This is actually strictly equivalent, the argument name being an arbitrary name. We choose here to call it `robot` in order to avoid a confusion when dealing with multiple robots. The only important thing is that you use the same name in the function body (i.e `robot` here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a fifth behavior for obstacle avoidance, where obstacles are walls, pilars, trees and cups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"s_obstacles\", \"b_obstacles\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open V-REP and load the scene `robot-scene-4.ttt` located in the directory `robotics/pyvrep_robot/vrep-scenes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** First import the functions `open_session` and `close_session`. Then, obtain a reference to the simulator and the E-Puck by calling `open_session`. Since there are three robots in the scene, we call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "from vivarium.utils.handle_server_interface import start_server_and_interface, stop_server_and_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cleger/Desktop/code/vivarium/vivarium/utils\n",
      "\n",
      "STARTING SERVER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-02 18:45:16,291][__main__][INFO] - Scene running: session_4\n",
      "[2024-12-02 18:45:18,836][vivarium.simulator.simulator][INFO] - Simulator initialized\n",
      "\n",
      "STARTING INTERFACE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 18:45:21,678 Starting Bokeh server version 3.3.4 (running on Tornado 6.4)\n",
      "2024-12-02 18:45:21,678 User authentication hooks NOT provided (default user enabled)\n",
      "2024-12-02 18:45:21,679 Bokeh app running at: http://localhost:5006/run_interface\n",
      "2024-12-02 18:45:21,679 Starting Bokeh server with process id: 70767\n"
     ]
    }
   ],
   "source": [
    "start_server_and_interface(scene_name=\"session_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cleger/Desktop/code/vivarium/venv/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measuring the FPS (number of steps per second) in the controller during 2 seconds ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 31.00\n"
     ]
    }
   ],
   "source": [
    "controller.print_fps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then execute the code you will encounter in the notebook or the code you will write for answering the questions. Whenever you want to restart from scratch (e.g. because something goes wrong or because you want to restart from scratch), first close the session by executing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will properly close all the running processes. Then restart the notebook (`Kernel -> Restart`) and open the session again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you will restart with a clean session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergent behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running one or several behaviors on a robot, you might observe behavioral responses that are not present in any of the behavior definitions. This usually doesn't mean that there is a bug, it could just be the result of an emergent behavioral property. Let's analyze this on a quick example, by running the `obstacle_avoidance` behavior on each robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in controller.agents:\n",
    "    agent.attach_behavior(obstacle_avoidance)\n",
    "    agent.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available behaviors: ['obstacle_avoidance'], Active behaviors: ['obstacle_avoidance']\n",
      "Available behaviors: ['obstacle_avoidance'], Active behaviors: ['obstacle_avoidance']\n",
      "Available behaviors: ['obstacle_avoidance'], Active behaviors: ['obstacle_avoidance']\n"
     ]
    }
   ],
   "source": [
    "for agent in controller.agents:\n",
    "    agent.print_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update agents diet\n",
    "for agent in controller.agents:\n",
    "    agent.diet = [\"resources\"]\n",
    "\n",
    "# Start resources apparition\n",
    "controller.start_resources_apparition(interval=60)\n",
    "\n",
    "# Start the eating mechanism\n",
    "controller.start_eating_mechanism(interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell above is a shortcut to execute the same set of instructions (the indented lines) on all the robots returned by the `open_session` function (the one you use to connect to the simulator). It can become very useful when you want to run the same set of instructions on all the robots, as it is the case here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** You will observe that the robots seem to be attracted to objects that are not handled by the behavior (e.g. other robots). Analyse this phenomena and explain below why it is occuring in a few lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click on this cell to enter your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing robot interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the interaction between two robots that run different behaviors. First close the current session and open a new one with only two robots that will be controlled (the third robot is still part of the scene but we don't need it here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_0 = controller.agents[0]\n",
    "robot_1 = controller.agents[1]\n",
    "robot_2 = controller.agents[2]\n",
    "\n",
    "# add a specific list for robots 0 and 1\n",
    "robots_lst = [robot_0, robot_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting attributes for robot 0\n",
      "setting attributes for robot 1\n"
     ]
    }
   ],
   "source": [
    "for robot in robots_lst:\n",
    "    print(f\"setting attributes for robot {robot.idx}\")\n",
    "    robot.diameter = 7\n",
    "    robot.color = \"cyan\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** In addition to the `obstacle_avoidance` behavior, run several combinations of the four other behaviors defined above. For example, run `obstacle_avoidance` and `fear` on `robot1` ; and `obstacle_avoidance` and `aggression` on `robot2`. Find two of these combinations that you consider as interesting (e.g. because they result in a relatively complex interaction pattern, or because they can be linked to animal behavior) and describe them in a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the previous session, it is possible to run several behaviors in parallel on the same robot. When doing it, the motor activation sent to each wheel corresponds to the average of the motor activation returned by each behavior (this averaging is implemented internally, you don't need to worry about it). \n",
    "\n",
    "It is also possible to specify the weight of each running behavior, i.e. how much it will count in the averaging. This is done by returning three values in the function defining a behavior (instead of two as we were doing until now: one for the left wheel activation and one for the right one). For example, if we want to run the `obstacle_avoidance` behavior with a weight of 1 and the `fear` behavior with a weight of 0.5, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spawn_entity_routine': (functools.partial(<function spawn_entity_routine at 0x7ddf7e76d360>, entity_type=1, position_range=None), 60), 'eating_routine_range': (<function eating_routine_range at 0x7ddefc502830>, 10)}\n"
     ]
    }
   ],
   "source": [
    "print(controller.routine_handler._routines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulator is already stopped\n"
     ]
    }
   ],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update agents diet\n",
    "for agent in controller.agents:\n",
    "    agent.diet = [\"resources\"]\n",
    "\n",
    "# Start resources apparition\n",
    "controller.start_resources_apparition(interval=60)\n",
    "\n",
    "# Start the eating mechanism\n",
    "controller.start_eating_mechanism(interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "attaching behaviors for robot 0\n",
      "Available behaviors: ['obstacle_avoidance', 'fear'], Active behaviors: ['obstacle_avoidance', 'fear']\n",
      "\n",
      "attaching behaviors for robot 1\n",
      "Available behaviors: ['obstacle_avoidance', 'fear'], Active behaviors: ['obstacle_avoidance', 'fear']\n"
     ]
    }
   ],
   "source": [
    "# First detach all behaviors on both robots:\n",
    "for robot in robots_lst:\n",
    "    robot.detach_all_behaviors()\n",
    "    robot.stop_motors()\n",
    "    \n",
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"s_obstacles\", \"b_obstacles\"])\n",
    "    return 1 - right, 1 - left\n",
    "\n",
    "# Attach and start both behaviors on both robots:\n",
    "for robot in robots_lst:\n",
    "    print(f\"\\nattaching behaviors for robot {robot.idx}\")\n",
    "    robot.attach_behavior(obstacle_avoidance, weight=1)\n",
    "    robot.attach_behavior(fear, weight=0.5)\n",
    "    robot.start_all_behaviors()\n",
    "    robot.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, the wheel activations returned by the `obstacle_avoidance` behavior will have twice more weight than those returned by the `fear` behavior. For example, if `obstacle_avoidance` returns 0.6 for the left wheel, and `fear` returns 0.9, then the total activation of that wheel will be $(0.6 * 1 + 0.9 * 0.5) / (1 + 0.5) = 0.7$ (i.e. the average of both values weighted by their respective activation). Note that when no weight is provided in a behavior definition (i.e. when the behavior function returns only two values as usual), the corresponding behavior is set with a default weight of one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors according to internal states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weighting is particularly useful to activate a behavior according to some internal states of the robot. Let's consider a robot that eats spheres (as in the previous session) and that eating those spheres allows to raise a simulated energy level of the robot. We want to continuously compute the energy level of the robot according to how much spheres it has recently eaten. To do so, we first need a way to know when a robot has eaten for the last time. There are several ways of doing this that can serve in different use cases:\n",
    "\n",
    "- agent.has_eaten(): function that tells if the agent has eaten since the last call to this function, defaults to False\n",
    "- agent.time_since_feeding: attribute that tells the time since the last meal, defaults to infinity when the agent has never eaten\n",
    "- agent.has_eaten_since(t): function that tells if the agent has eaten since time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "inf\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(robot_2.has_eaten())\n",
    "print(robot_2.time_since_feeding)\n",
    "print(robot_2.has_eaten_since(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do it for all robots at once :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robot 0: -ate: False -time since feeding: 502\n",
      "True\n",
      "robot 1: -ate: False -time since feeding: 1872\n",
      "False\n",
      "robot 2: -ate: False -time since feeding: 1012\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for robot in controller.agents:\n",
    "    print(f\"robot {robot.idx}: -ate: {robot.has_eaten()} -time since feeding: {robot.time_since_feeding}\")\n",
    "    print(robot.has_eaten_since(503))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.pause()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above return `True` if the robot (`robot1` here) has eaten a sphere since the last call of the function. Run both the `obstacle avoidance` and the `foraging` behavior on an robot and execute the `has_eaten` function above at different times to understand correctly how it works. Remember we have already defined a `foraging_behavior` in the last session, which can be implemented like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foraging(robot):\n",
    "    left, right = robot.sensors(sensed_entities=[\"resources\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measuring the FPS (number of steps per second) in the controller during 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 26.00\n"
     ]
    }
   ],
   "source": [
    "controller.print_fps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start sphere apparition faster in the environment:\n",
    "controller.stop_resources_apparition()\n",
    "controller.start_resources_apparition(interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detach all existing behaviors, and attach then start obstacle_avoidance and foraging on all robots:\n",
    "for robot in controller.agents:\n",
    "    robot.detach_all_behaviors()\n",
    "    robot.attach_behavior(obstacle_avoidance, interval=10)\n",
    "    robot.attach_behavior(foraging, interval=10)\n",
    "    robot.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to continuously compute the energy level of a robot, so that the level decreases slowly when nothing is eaten and increases whenever food is consumed. This can be done by attaching and starting a *routine* to a robot. The definition of a routine is very similar to the definition of a behavior, except that it doesn't return any value (whereas a behavior always returns the left and right wheel activations, and optionally a weight). Thus, a routine corresponds to a set of instructions that are executed at a particular frequency (as in a behavior), e.g. to compute some robot's internal states according to its interaction with the environment.\n",
    "\n",
    "Let's define a routine called `foraging_drive` that computes the energy level as specified above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment : \n",
    "\n",
    "- Old values were really little and hard to keep energy level > 0 \n",
    "- did that atm but will be changed (just for testing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_energy_level = 100.\n",
    "init_energy_level = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 energy level is: 50.0\n",
      "Agent 1 energy level is: 50.0\n",
      "Agent 2 energy level is: 50.0\n"
     ]
    }
   ],
   "source": [
    "for agent in controller.agents:\n",
    "    agent.energy_level = init_energy_level\n",
    "    print(f\"Agent {agent.idx} energy level is: {agent.energy_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foraging_drive(robot): \n",
    "    if robot.has_eaten():\n",
    "        # increase size and energy level\n",
    "        robot.energy_level += 10  # if the robot has eaten a sphere, increase its energy level by 0.2\n",
    "        robot.diameter += 0.5\n",
    "    else:\n",
    "        # decrease energy level\n",
    "        robot.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level by 0.01\n",
    "    # The line below bounds the value of the energy level between 0 and 1\n",
    "    robot.energy_level = min(max_energy_level, max(robot.energy_level, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, the function defining a routine takes a `robot` as an argument representing the robot on which the routine is attached. Attaching a routine is done with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign foraging_drive to robot_0 and give him a specific color to recognize him\n",
    "robot_0.attach_routine(foraging_drive)\n",
    "robot_0.color = \"black\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, a routine is attached to an robot at a given frequency. However, contrary to behaviors, routines are not directly involved in motor control and therefore can be run at a lower frequency (1Hz above). The code of the `foraging_drive` function above will be executed each second (1Hz frequency), consequently modulating the robot energy level stored in `robot.energy_level` according to how good the robot is at catching spheres.\n",
    "\n",
    "Before starting a routine, we need to define an initial level of energy. Let's do it on `robot1`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment : \n",
    "\n",
    "- the start object apparition works well but often you need to call it a lot of times\n",
    "- bc it either spawns the objects too slowly or bc too fast\n",
    "- and then stops when the max objects have been placed in the scene\n",
    "\n",
    "--> Could find another way to make this feature better for users (e.g not stopping the fn even when the max objects have been reached, and have to call stop objects apparition so it stops) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mandatory because `energy_level` is incremented or decremented in the `foraging_drive` definition. If not initialized, it will throw an error.\n",
    "\n",
    "Let's now effectively start this routine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the evolution of the energy level in `robot_0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.18000000000016\n"
     ]
    }
   ],
   "source": [
    "print(robot_0.energy_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.05000000000019\n"
     ]
    }
   ],
   "source": [
    "print(robot_0.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the robot behave in the environment and re-execute the cell above to track the evolution of the energy level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Modify the `foraging` behavior so that it is weighted according to the energy level of the robot: the lower the energy level, the higher `foraging` is weighted. However, as seen in Q1 above, the robot might still be attracted to spheres even when the `foraging` weight is null. Solve this issue by adding another behavior that drives the robot away from sphere according to the energy level: the higher the energy level, the more the robot is repulsed from spheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to allow a robot to sense attributes from other robots. For example, one might want to define different species of robot (cats and mouses for example) so that how a robot interact with another depends on their respective species. To achieve this, it is **not** recommended to modify the robot labels directly in V-REP (as a general rule, never modify the object labels in the VREP scene). Instead, each robot can be set with a specific attribute, e.g `robot.species = \"cat\"` and that attribute can be sensed by other robots whenever it is detected by a proximeter. Let's try it with three robots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# close_session(simulator)\n",
    "# simulator, robot1, robot2, robot3 = open_session(n_robots=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we define a `species` attribute for each robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "robot_0.species = \"cat\"\n",
    "robot_0.diameter = 12.\n",
    "robot_0.color = \"red\"\n",
    "robot_0.can_eat = False\n",
    "\n",
    "robot_1.species = robot_2.species = \"mouse\"\n",
    "robot_1.diameter = robot_2.diameter = 7.\n",
    "robot_1.color = robot_2.color = \"cyan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one cat and two mouses. Place the robots so that `robot3` (mouse) is sensing `robot1` (cat) on its left proximeter and `robot2` (mouse) on its right proximeter. One can access attributes of sensed robots by first executing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell above calls the `prox_activations` function of `robot3` with an additional argument, `return_robots`, which is set to `True`. When called like this, `prox_activations` will return the left and right proximeter activations as usual, as well as the references to the robots that are sensed by the proximeters, if any. Then we can access a specific attribute of those robots by executing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return sensed entities by left and right proximeters, we can use the `sensed_entities` function of the agents. This returns the left and right entities if they are sensed, and `None` otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_l, ent_r = robot_0.sensed_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check what are the entities detected by a robot by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left entity:\n",
      "No entity sensed\n",
      "\n",
      "Right entity:\n",
      "Entity Overview:\n",
      "--------------------\n",
      "Type: OBJECT\n",
      "Subtype: resources\n",
      "Idx: 9\n",
      "Exists: True\n",
      "Position: x=172.37, y=274.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Give a specific color to robot_0 to recognize him\n",
    "robot_0.color = \"black\"\n",
    "# Sense entities on the left and right of robot_0\n",
    "ent_l, ent_r = robot_0.sensed_entities()\n",
    "\n",
    "# Print the infos of the sensed entities\n",
    "print(\"Left entity:\")\n",
    "if ent_l:\n",
    "    ent_l.print_infos()\n",
    "else:\n",
    "    print(\"No entity sensed\")\n",
    "\n",
    "print(\"\\nRight entity:\")\n",
    "if ent_r:\n",
    "    ent_r.print_infos()\n",
    "else:\n",
    "    print(\"No entity sensed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly sense specific attributes of these sensed entities with the `sense_attributes` function. Make sure to specify the `sensed_attribute` you want to sense (e.g 'diameter', 'species', etc.). You can also specify the `default_value` value to return if the attribute is not found (otherwise it is set to None). The function will return the given attribute of the left and right sensed entities if it exists (it can be either if the entity doesn't exist, or because the entity doesn't possess the specific attribute), and the default value otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, each entity has a diameter, so if you see a `None` value, it means that the entity isn't sensed by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: None Right: 5.0\n"
     ]
    }
   ],
   "source": [
    "l_attr, r_attr = robot_0.sense_attributes(sensed_attribute=\"diameter\",)\n",
    "print(f\"Left: {l_attr} Right: {r_attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this other case, we only defined species for the robots. We set the default value to 'unknown', so if an entity isn't detected, or doesn't have the attribute, it will return 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: unknown Right: unknown\n"
     ]
    }
   ],
   "source": [
    "l_attr, r_attr = robot_0.sense_attributes(sensed_attribute=\"species\", default_value=\"unknown\")\n",
    "print(f\"Left: {l_attr} Right: {r_attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sensed_robot_attributes` function takes 4 arguments: the robot sensed by the left proximeter (called `robot_left` in the example above), the one sensed by the right proximeter (called `robot_right` above), the name of the attribute we are interested in (here `\"species\"`) and the default value to return if a proximeter is not sensing any robot (here `none`).\n",
    "\n",
    "Move the robots in the scene and check how the attribute sensing is changing accordingly by re-executing the two above cells. Then try with other attributes, for example by setting a `age` attribute to the robots and sensing it from the proximeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extend the `fear` behavior so that mouses are only afraid by the cat but not by the other mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fear_cat(robot):\n",
    "    (left, right) = robot.sensors(sensed_entities=[\"robots\"])\n",
    "    left_species, right_species = robot.sense_attributes(sensed_attribute=\"species\", default_value =\"none\")\n",
    "    left_activation = left if left_species == \"cat\" else 0\n",
    "    right_activation = right if right_species == \"cat\" else 0\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run this behavior together with the `obstacle_avoidance` one on `robot3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_2.detach_all_behaviors()\n",
    "robot_2.attach_behavior(obstacle_avoidance)\n",
    "robot_2.attach_behavior(fear_cat)\n",
    "robot_2.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available behaviors: ['obstacle_avoidance', 'fear_cat'], Active behaviors: ['obstacle_avoidance', 'fear_cat']\n"
     ]
    }
   ],
   "source": [
    "robot_2.print_behaviors()\n",
    "robot_2.color = \"silver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `robot3` (mouse) is now avoiding `robot1` (cat) but not `robot2` (mouse). We can modify the `species` attribute of robots on the fly. Let's swap the species of `robot1` and `robot2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "robot_0.species = \"mouse\"\n",
    "robot_1.species = \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `robot3` (mouse) is now avoiding `robot2` (cat) but not `robot1` (mouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Use the new functionalities we have seen in this session to design the following system:\n",
    "Two robots are equipped with behaviors to avoid obstacle and catch spheres, as well as being attracted or repulsed by the other robot. Attraction and repulsion depend on the energy level of the other robot: the higher this level the more attraction, the lower this level the more repulsion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ag in controller.agents:\n",
    "    ag.detach_all_behaviors(stop_motors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: Modify the previous simulation such that attraction and repulsion depend on how much a robot has been close to others in the recent past. To do so, define a `social_drive` routine that modulates the value of a `social_need` attribute in each robot. This social need continuously increases when other robots are far and decreases when a robot comes closer to its conspecifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_server_and_interface()\n",
    "controller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you finished this session, you can either jump to :\n",
    "\n",
    "- [session 5](session_5_bonus.ipynb) : Bonus session that explains how to use routines to a simple Eco-Evolutionary simulation\n",
    "- [session 6](session_6_logging.ipynb) : How to log and plot data about the simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## About the mini-project\n",
    "\n",
    "The aim of the mini project is to show that you have understood all the concepts we have seen during these three practical sessions and that you can integrate them in a single demo. You can of course modify the V-REP scene at your will, e.g adding cups or trees. Don't forget to save you modified V-REP scene (`File -> Save scene as` in V-REP). You can start your project in a new Jupyter Notebook (`File -> New notebook -> Python3`) in the menu bar at the top of this notebook). Use both text cells (explaining what you are doing) and code cells (with the corresponding code to execute).\n",
    "\n",
    "Therefore, your project will consists of two files: a V-REP scene (extension `.ttt`) a Jupyter Notebook (extension `.ipynb`). Don't forget to save them, e.g. on a USB stick, before logging out from the UPF computers. See [this slide](https://docs.google.com/presentation/d/1FlAUyvNynYU4mDBE2o20pf2Bn5PC_9Id3SK8sCMfr-Q/edit#slide=id.g34900c6ead_0_0) for more information on the mini-project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
