{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 3: Parallel behaviors and more sensing abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session, we saw how to define, attach, start, stop and detach a behavior on an agent agent. We implemented three distinct behaviors: `slow_down`, `fear` and `aggression`.\n",
    "\n",
    "In this section we will see more sensing abilities the agent is equipped with, will define new behaviors using them and will see how to deal with multiple behaviors running in parallel on the same agent. At the end of the session, we will also see how to attach those behaviors on multiple agents interacting together within a Vivarium scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, start the server, the interface and open the simulator session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "from vivarium.utils.handle_server_interface import start_server_and_interface, stop_server_and_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_server_and_interface(scene_name=\"session_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the interface link shows up (http://localhost:5006/run_interface) and click on it, and make sure the scene is present on your browser. You should now only see one agent in the environment. If it is the case, you can ignore this instruction and skip to the next cell.\n",
    "\n",
    "Else, if you see two agents, it means a plotting error happened, and that simulations that shouldn't exist are still displayed. To fix it, open the `SIMULATOR` tab of the interface. Inside this tab, untick the `Hide non existing` checkbox, and tick it again. The scene should now be displayed correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a controller that will be used to control the simulation with Python code from this jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectively detecting scene objects\n",
    "\n",
    "To define a repertoire of interesting behaviors, we need the agent to selectively sense the proximity of different types of entities around them. For example, we might want to define a behavior for obstacle avoidance and another one for attraction towards mates. The first behavior will require sensors information about objects, whereas the second will require the proximeters to detect other agents (although there is only one agent in the scene for now, we'll add more at the end of this session). \n",
    "\n",
    "Since there is only one agent, let's create an alias variable to access it as in previous sessions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = controller.agents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the agent turn on itself, and call the `sensors` function with different orientations of the agent to test it works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the agent turn on itself\n",
    "agent.left_motor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, ensure the following cell gives different values each time you call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = agent.sensors()\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in interface, there are three types of entity in the current scene: a blue circle and a number of orange and green squares. By default in Vivarium, circle entites represent agents and square entities represent objects. Here we have two subtypes of objects: large orange ones and smaller green ones. In this sessions, we call the orange objects \"obstacles\" and the green objects \"resources\". \n",
    "\n",
    "We can print the names of the existing subtypes in the scene with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.print_subtypes_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for informaiton, the types (agent or objects), subtypes (agents, obstacles or resources) and their respective colors are defined in a scene configuration file. The configuration file of the current scene is located at [conf/scene/session_3.yaml](../../conf/scene/session_3.yaml). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the result returned by the agent's proximeters by providing the argument `sensed_entities` to the `sensors` function. Let's detect only one type of entities (e.g obstacles). It should only return positive values when the proximeters are sensing the obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"obstacles\"])\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the cell above will return the proximeter activations only for the `obstacles` entities (the orange squares in the scene). Give it a try by first stopping the agent wheels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop_motors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then move an obstacle in the detection area of the proximiters and re-executing the cell above that calls `agent.sensor(.)` to observe the change in the returned values. You can also check that the proximeter activations are not modified by other objects such as ressources (little green squares).\n",
    "\n",
    "Note that selective sensive can be occluded by other entities, whatever their subtype. This mean that if e.g. a `resource` object is closer than any `obstacle` object in the proximiter field of view, then `agent.sensors(sensed_entities=[\"obstacles\"])` will return `0` for that proximiter. This is somehow similar to how our own eyes sense objects: if you look at a tree but there is a wall between the tree and yourself, you won't see that tree. \n",
    "\n",
    "The `sensed_entities` argument requires a list of strings (`[\"obstacles\"]` in the example above). In Python, a list is a collection of values separated by commas and surrounded by square bracket: `[\"obstacles\"]` is therefore a list of only one element (the string `\"obstacles\"`), whereas `[\"obstacles\", \"agents\"]` is a list of two elements (the strings `\"obstacles\"` and `\"agents\"`). \n",
    "\n",
    "The `sensed_entities` argument, as its name indicates, specifies the entities to be sensed by the proximeters. You can get the subtype of any entity in the scene by using the `print_infos` function, and looking at the `Subtype` field. For example, select the object with index `0`in the interface (you can do this by clicking on `0` in the `Selection` list of the `OBJECT` column on the interface). You check the subtype of the object with index `0` with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_idx = 0  # index of the object of interest\n",
    "object = controller.objects[object_idx]  # get the object of interest\n",
    "object.print_infos()  # print the object's information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the object you selected in the interface was a green square (resp. an orange square), the subtyte printed above should `resources` (resp. obstacle). Alternatively you can also look at the value of the `Subtype` field at the bottom of the `OBJECT` column in the interface. Here the subtype is encoded as an integer, which correspond to the order in which subtypes are defined in the scene configuration file (the yaml file mentioned above), starting at `0`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the same for the agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_infos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An agent's sensor can also detect multiple subtypes of entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"resources\", \"obstacles\"])\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case it will sense the closest entities that are of one of the indicated subtype (i.e. here the closest entities which are either resources or obstacles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives an error message if you provide a string that doesn't correspond to an existing subtype or that is spelled wrong, and ask you to select a type among the correct ones :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = agent.sensors(sensed_entities=[\"resssources\"])  # typo in the entity subtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** Write the code printing the proximeter activations for resources and test that it works as expected by placing your agent close to those objects and verifying the returned values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Define an `obstacle_avoidance` behavior. The agent has to turn in the direction opposite to the obstacles it detects, with its speed inversely proportional to the proximeter activations (the closer an obstacle, the lower the speed). \n",
    "*Tip:* it is similar to the `shyness` behavior of [Braitenberg vehicles](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that to test a behavior, you first have to detach all behaviors that could still be attached to the agent, then to attach the new one, that is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()\n",
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent should now smoothly navigate between the obstacles in the scene. You can now detach this behavior and stop its motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors(stop_motors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environmental dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, the environment in which the agent is evolving was quite static: although some objects can be pushed by the agent (e.g. the obstacles or the resources), there is nothing that appears or disappears in the environment. We are now going to see how we can generate food sources appearing at random positions in the environment and disappearing whenever a agent eats them. A food source is modeled as a `resources` object (the green squares). Before making these resources spawn, we need to do a few things before implementing a mechanism where the agent will eat ressources :\n",
    "\n",
    "- Add `resources` to the agent's diets\n",
    "- Start the eating mechanism with the controller\n",
    "- Start the apparition of `resources` with the controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the diet of agents\n",
    "\n",
    "First, let's handle the diet of the agent, we can check his current diet and eating range with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAgent eating information:\")\n",
    "print(f\"Current agent diet: {agent.diet}\")\n",
    "print(f\"Current agent eating range: {agent.eating_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diet of the agent is a list of entity subtypes the agent can it. As we see above the list is currently empty, which means that our agent is not able to eat anything. \n",
    "\n",
    "The default eating mechanism in Vivarium is pretty basic: an agent will eat an entity whose subtype is in its diet whenever that entity is at a distance lesser than the specified eating range. As seen above, the current eating range is 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get theses informations by using the print_infos() function, with `full_infos` set to True (but it will also print a lot of other informations you might not be interested in): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_infos(full_infos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then manually add ressources to the agent's diet, by setting it in a list of strings, as for the `sensed_entities` argument of the `sensors` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.diet = [\"resources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted them to eat other kind of entities such as obstacles, we would have to add `obstacles` to the diet list of the agents.\n",
    "\n",
    "Now the agent will eat resources, i.e. the green squares, whenever they are within their eating range. But to enable it we first need to start the eating mechanism as explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the eating mechanism\n",
    "\n",
    "To enable the eating mechanism we need to start it on the controller with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_eating_mechanism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, whenever a resource is within the eating range of the agent, it will \"eat\" it. This means that the resource will disappear from the environment once eaten. The agent will also receive an internal signal indicating it has eaten something, which we will explain it later. You can test that resources indeed disappear once eaten by manually moving the agent close to a resource (either by setting motor activation in the notebook or with drag n drop in the interface)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start spawning of resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to make this scene more interesting, we can start ressources spawn, i.e. regularly adding new resources in the environment. To do so, we need to specify an interval of simulation steps between each apparition of a resource. To estimate what this interval could be, we can use the `print_fps` method of the controller to know how many steps per seconds are executed in the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.print_fps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. if we want a resource to appear every 2 seconds, we will set the interval to 2 * FPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace by your actual fps value\n",
    "fps = 30\n",
    "seconds = 2\n",
    "interval = seconds * fps\n",
    "print(interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, start the spawning of resources with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_resources_apparition(interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()\n",
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resources should now appear at random positions in the scene. This will be done until the maximum number of resources is reached in the environment (it is set to 12 for this session). If this is the case and the agent eats a resource somewhere, another one will appear at a random position in the scene.\n",
    "\n",
    "You can also stop the spawning of resources with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop_resources_apparition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to, you can also remove all the entities of a certain type with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.remove_entity_type(\"resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the resource apparition function is still running, the controller will keep spawning resources even after removing them with the previous cell. When executing the previous cell it might print messages such as `Entity x already removed`, don't worry about those for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom position of resources spawning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also control the position range where the resources will appear with the `position_range` parameter. This parameter is a list of 4 values: ((x_min, x_max), (y_min, y_max)) where x_min and x_max are the minimum and maximum x coordinates of the spawning area, and y_min and y_max are the minimum and maximum y coordinates of the spawning area. For example, to make resources appear only in the area between x=0 and x=50, and y=100 and y=200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, start the spawning apparition in a specific area\n",
    "controller.start_resources_apparition(interval=interval, position_range=((0, 50), (100, 200)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above will generate resources at random 2D positions $(x, y)$ in the scene with $x\\in[0, 50]$, $y\\in[100, 200]$ (analyze the cell above to understand how the `position_range` argument is converted in $(x, y)$ intervals and ask us if it is not clear). You can easiely check the coordinate of an entity in the web interface.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Write the code that removes the resources from the environment, and make them appear in the bottom-right corner of the scene (approximately the quarter of the environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with this mechanism a bit, and then stop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop_resources_apparition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Define a behavior allowing the agent to catch food sources, let's call it `foraging`. The agent has to orient itself toward food sources, with a speed proportional to the proximiter activations (the closer the food source, the higher the speed) \n",
    "\n",
    "- *Tip 1:* It's similar to the `aggression` behavior. \n",
    "- *Tip 2:* You already saw how to detect `obstacles` in the obstacle avoidance behavior. Here the agent will instead have to detect `resources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach and start the behavior on the agent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First detach previous behaviors that might still be attached to the agent\n",
    "agent.detach_all_behaviors()\n",
    "\n",
    "# Write the code to attach and start the `foraging` behavior below\n",
    "agent.attach_behavior(foraging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a resource is detected by the proximeters, the agent should go towards it. However, if at one point the proximeters don't detect any resource, the agent will probably stop (depending on how you have defined the behavior). The only event that could make the agent move again would be a resource that spawns within the proximeter detection area, which is not very likely to happen (and therefore quite a bad option if the survival of the agent depends on its foraging abilities). \n",
    "\n",
    "A solution to avoid such a blocking situation is to combine the `foraging` behavior with another one that keeps the agent in movement, as it is for example the case of the `obstacle_avoidance` behavior we have defined before. Let's attach and start the `obstacle_avoidance` behavior, but this time without detaching the previously attached `foraging` behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.attach_behavior(obstacle_avoidance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we haven't detached the previous behavior, the agent is now executing two behaviors in parallel. This can be checked with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which tells us that both behaviors are attached and started. In V-REP, you can see that the agent is now both foraging and avoiding obstacles. For doing so, the motor activation sent to each wheel corresponds to the average of the motor activation returned by each behavior (this averaging is implemented internally, you don't need to worry about it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with multiple agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explains how to deal with multiple agents and how to attach different behaviors to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment there is only 1 existing agent that we can see in the scene. But there is actually another one that is not \"existing\" yet. We can see it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which returns a list with two elements in it, each one corresponding to an agent. The first element in the list is accessed with `controller.agent[0]` (in Pythons list indices starts at 0) and corresponds to the agent we have manipulated above (using the alias variable `agent` which was set to `controller.agent[0]` at the start of this notebook). We can check if this first agent exists with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.agents[0].exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is `True`, meaning that this agent exists (it is the one we see in the interface). Let's check it for the second agent (index `1` of the list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.agents[1].exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is `False`, meaning that this agent does not exist yet. We can make this agent exist with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.agents[1].exists = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should see a second agent in the interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will rename our original `agent` to `agent_0` and the new one to `agent_1` to make things clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0 = controller.agents[0]\n",
    "agent_1 = controller.agents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`agent_0` is the same as the one we called `agent` before: you can see it moving the same in the interface, and also check he still has the same behaviors attached to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the color of the second agent to be red, so that we can differentiate it from the first one, and also add the 'resources' to its diet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1.color = 'red'\n",
    "agent_1.diet = [\"resources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have access to the two agents through the variables `agent_0` and `agent_1` (these variables names are arbitrary, you can choose whatever you want, e.g. `predator` and `prey`). You can attach and start behaviors on each agent independently, in the same way as you did before, simply using either the `agent_0` and `agent_1` variables instead of only `agent` one as before.\n",
    "\n",
    "As an example, let's say we want to attach the `obstacle_avoidance` behavior we have defined above to `agent_0`, and both the `obstacle_avoidance` and the `foraging` behaviors to `agent_1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach the agent_0 behaviors and only attach the obstacle_avoidance behavior\n",
    "agent_0.detach_all_behaviors()\n",
    "agent_0.attach_behavior(obstacle_avoidance)\n",
    "print(\"\\nAgent_0 behaviors:\")\n",
    "agent_0.print_behaviors()\n",
    "\n",
    "# attach the obstacle_avoidance and foraging behaviors to agent_1\n",
    "agent_1.attach_behavior(obstacle_avoidance)\n",
    "agent_1.attach_behavior(foraging)\n",
    "print(\"\\nAgent_1 behaviors:\")\n",
    "agent_1.print_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the resources apparition mechanism again to see if `agent_1` (i.e. the red one) is able to catch the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.start_resources_apparition(interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Implement the `fear` and `aggression` behaviors so that they are directed only toward the other agent, using the `sensed_entities` argument of the `sensors` method as we have seen above. Then attach both the `obstacle_avoidance` and the `aggression` behaviors to one agent, and both the `obstacle_avoidance` and the `fear` behaviors on the other. If you did it well, you should observe a simple \"prey-predator\" interaction, where `agent_0` tries to catch `agent_1` and `agent_1` tries to escape from `agent_0`.\n",
    "\n",
    "First, you can detach the behaviors and stop the motors of both agents with the following cell. Using this `for` loop on the `controller.agents` and the `detach_behaviors` function enables you to detach the behaviors of all the agents at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `fear` and `aggression` behaviors towards other agents in the cell below.\n",
    "\n",
    "- *Tip 1:* You already saw how to define `aggression` behavior toward every entity in session 2. \n",
    "- *Tip 2:* You now want to fear and agress other agents, you might want to specificaly sense them here. The agents are of subtype `agents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the cell below to attach the previously defined behaviors to the agents. We also directly provide lines of code to modify the aspect of the agents (size, color) and their speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach the aggression and obstacle_avoidance behaviors to agent_0, and increase its diameter\n",
    "# your code here\n",
    "agent_0.diameter = 10.\n",
    "agent_0.color = 'red'\n",
    "agent_0.wheel_diameter = 3.0\n",
    "\n",
    "# attach the fear and obstacle_avoidance behaviors to agent_1, decrease its diameter, and increase its speed\n",
    "# your code here\n",
    "agent_1.diameter = 4.\n",
    "agent_1.color = 'cyan'\n",
    "agent_1.wheel_diameter = 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that `agent_0` is chasing `agent_1` when it detects it, and that `agent_1` is avoiding `agent_0`. They should be both avoiding obstacles as well. If the presence of obstacles and resources is perturbating, we can remove them from the scene with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop_resources_apparition()\n",
    "\n",
    "controller.remove_entity_type(\"obstacles\")\n",
    "controller.remove_entity_type(\"resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the sensor fields of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But because the sensors of `agent_1` are only directed in the forward direction, it is really hard to avoid the `agent_0` when it comes from behind it (it cannot see it in that case). Additionally, the `agent_0` is a predator but has a pretty bad vision because it can't see very far.\n",
    "\n",
    "\n",
    "We can fix this by modifying the sensors characteristics of the agents, by changing their angles and max ranges by using the following cell. \n",
    "\n",
    "- The `prox_dist_max` parameter is the maximum distance at which the sensors can detect entities\n",
    "- The `prox_cos_min` parameter is the minimum cosine of the angle between the sensor and the entity in order to detect it\n",
    "\n",
    "So the `prox_cos_min` value is between -1 and 1. The closer this value is to 1, the narrower the sensor field of view, and inversely for -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the range of the big agent and decrease its angle\n",
    "agent_0.proxs_dist_max = 100.\n",
    "agent_0.proxs_cos_min = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the range of the small agent and increase its angle\n",
    "agent_1.proxs_dist_max = 40.\n",
    "agent_1.proxs_cos_min = -0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for today. Don't forget to properly close the simulator before closing this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop()\n",
    "stop_server_and_interface(safe_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you finished session 3, you can now jump to the notebook of [session 4](session_4.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
