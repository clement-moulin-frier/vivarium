{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 2: Implementing reactive behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminders :** \n",
    "- Save your work as indicated at the beginning of the `session_1.ipynb` notebook.\n",
    "- Each time you encounter a cell containing code in this notebook (as in the cell starting with `from simulator_interface ...` below), you have to execute it by clicking on the cell and pressing `Shift+Enter` (unless it is explicitly specified not to do it).\n",
    "\n",
    "<!-- TODO: load scene !-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "import numpy as np\n",
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then start the simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run(threaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If at one point things are not going as expected (e.g. the agent doesn't move the way it should in the simulator), do the following steps:\n",
    "- Stop any code that can still be executing by pressing the \"stop-like\" button in the top menu bar of this document. \n",
    "- Stop the simulator by executing (no need to do it now though):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Restart the notebook by clicking `Kernel -> Restart` in the menu (sometimes doing it twice might help).\n",
    "- Re-open the session by executing (don't re-open it now if you haven't closed it by executing the previous cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "import numpy as np\n",
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an alias for the agent again since there is still only one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = controller.agents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session we saw how to set the agent left and right wheel speeds as well as how to read the values returned by the left and right proximeters. We programmed a first simple behavior where the agent slows down when approaching an obstacle. \n",
    "Here is a possible solution for this behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 1000 times the indented code:\n",
    "for i in range(1000):\n",
    "    # Read the proximeter values and store them in the \"left\" and \"right\" variables\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # Compute the sum of the values returned by the left and right proximeters.\n",
    "    # This sum will be between 0 and 2 because both \"left\" and \"right\" are between 0 and 1\n",
    "    sum_of_proxs = left + right\n",
    "    \n",
    "    # Compute the activation that will be applied to both wheels. \n",
    "    # The closer the obstacle (i.e. the higher the value returned by the proximeters), the lower the wheel activation should be.\n",
    "    # Note that wheel activation is bounded between 0 and 1\n",
    "    wheel_activation = 1.0 - sum_of_proxs / 2.0\n",
    "    \n",
    "    # Set the activation of both wheels to the value we just have computed\n",
    "    agent.right_motor = wheel_activation\n",
    "    agent.left_motor = wheel_activation\n",
    "    \n",
    "    # Waits for 100 milliseconds before starting the next iteration (to avoid overloading you computer)\n",
    "    controller.wait(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical definition of a behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example behavior defined above illustrates the general structure of a behavior. \n",
    "\n",
    "**Definition:** a behavior consists of a loop repeated at a certain frequency where (1) the values of relevant sensors are read, (2) some computation is performed using these values and (3) commands are sent to the agent motors according to the result of this computation.\n",
    "\n",
    "In the example above, the frequency of the behavior is approximately 10 Hz, i.e. the core of the loop is executed approximately 10 times per second (because we wait for 0.1s at the end of each iteration). This is an approximation because we don't take into account the time needed to execute the instructions occurring before the waiting period. Step (1) corresponds to the reading of the left and right proximeters activations. Step (2) corresponds to the computation of `wheel_activation` according to the sum of the proximeter activations. Finally, Step (3) corresponds to setting the speed of both motors to the value of `wheel_activation`.\n",
    "\n",
    "Note that the code above will take a while to be executed (approximately `1000 * 0.1 = 100` seconds, since the loop is repeated 1000 times). During this time, you can't execute anything else in this notebook. To stop the execution before it terminates by itself, you have to press the \"stop-like\" button in the top menu bar of this document. \n",
    "\n",
    "This approach has three major drawbacks:\n",
    "- Only one behavior can run at a time.\n",
    "- The behavior has a fixed duration (at one point it will stop)\n",
    "- We can't stop a behavior programmatically (instead we have to press the \"stop-like\" button).\n",
    "\n",
    "To overcome these problems, we provide a more flexible method for defining and executing behaviors. Let's rewrite the behavior above using that method. First make sure the previous code is not still being executed by pressing the \"stop-like\" button in the top menu bar of this document. Now, defining a behavior boils down to defining a function which includes the core of the behavioral loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this cell defines a function called slow_down (first line),\n",
    "# which takes as argument the agent (first line, in parenthesis),\n",
    "# and returns the left and right speed activation to be applied to the motors (last line)\n",
    "\n",
    "def slow_down(agent):\n",
    "    # Step (1): read the sensor values\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # Step (2): do some computation\n",
    "    sum_of_proxs = left + right\n",
    "    wheel_activation = 1.0 - sum_of_proxs / 2.0\n",
    "    \n",
    "    # Step (3): return the motor activations\n",
    "    return wheel_activation, wheel_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above defines a function called `slow_down`. In computer programming, a function is a sequence of instructions that perform a specific task depending on some parameters (called the arguments of the function) and that returns a result. In this sense it is very similar to the mathematical definition of a function, as for example when we write `y = f(x)`, where `f` is the name of the function, `x` is its argument, and `y` is the result.\n",
    "\n",
    "As seen above, the definition of a function in Python starts with the keyword `def`, followed by the arbitrary name we choose for the function (here we called it `slow_down` to reflect the purpose of the behavior defined in it). Then come the arguments of the function in parenthesis (in our case it will be the variable representing the agent, called `agent`) and finally the symbol `:`. Below the first line, you find the instructions that this function will execute when it will be called. Those instructions need to be intended right with respect to the first line. In this example, the instructions are the exact same as in the core of the previous `for` loop, except that:\n",
    "- we omit the last line `controller.wait(0.1)` (the frequency at which the behavior will be executed will be set in more rigorous way below),\n",
    "- we don't directly set the motor activations using `agent.left_motor` and `agent.right_motor`. Instead, we *return* the values of the motor activations in the last line and they will be automatically sent to the agent motors when the behavior will be executed. In the last line, the values after the `return` keyword have to be the left and right speed activation (in this order). Both activations have to be between 0 and 1. (In the `slow_down` behavior above, both activations are the same since we don't want the agent to turn).\n",
    "\n",
    "Note that a function definition, as the one above, does not execute the instructions contained in it, it only defines them so that they can be executed later when the function will be *called*. In our case, we will not explicitly call the function, instead it will be done behind the scene when we will start the behavior on the agent (see below).\n",
    "\n",
    "Once the behavior is defined as a function, we can attach it to the agent by executing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.attach_behavior(slow_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line above means: attach the behavior defined in the function `slow_down` to the `agent` and set the frequency at which it will be repeated to ~10Hz. Note that this instruction does not execute the behavior on the robot, it only informs the robot that the behavior is available to it.\n",
    "\n",
    "In order to actually start the behavior, we have to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.start_behavior(\"slow_down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the agent executing the exact same behavior as before (if the agent is already close to an obstacle, move it to a more open space to observe it slowing down).\n",
    "\n",
    "The line above means: start running the previously attached `slow_down` behavior on the `agent`. Executing the above line will basically do the same thing as executing the `for` loop at the start of this document. Here, the function `slow_down` will be executed at a frequency of 10Hz as set in the previous cell (i.e. 10 times per second), indefinitely. \n",
    "\n",
    "Using this method has the following advantages over the previous method using the `for` loop:\n",
    "- It is more compact to write and it will allow to better structure your code when you will have to deal with multiple behaviors and multiple agents.\n",
    "- It better manages the frequency at which the behavior is run. Now the behavior runs at exactly 10Hz, whereas in the previous method we could only approximate the true frequency.\n",
    "- It is not blocking as the previous method was. This means that you can still use this notebook while the behavior is running on the agent. For example, let's read the proximeter activations while the agent is still executing the `slow_down` behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9311789870262146, 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time you execute the cell above, you should see the proximeter activation changing because the agent is moving. However, you should avoid setting motor values while a behavior is running since this could conflict with the behavior also setting those values. When a behavior is started, it runs indefinitely until you explicitly tell it to stop. To do so, you have to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop_behavior(\"slow_down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the agent will continue moving using the last wheel speeds that were set by the behavior. You can set both wheel speeds to 0 by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop_motors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you don't want the behavior to be attached to the agent anymore (for example if you want to test another behavior), you can execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_behavior(\"slow_down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At anytime, you can check what behaviors are attached to the agent with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.check_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see what behaviors are started on the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.check_active_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** To make sure you correctly understand how to attach, start, stop and detach a behavior, complete the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we make sure that no behavior is attach to the agent:\n",
    "agent.detach_all_behaviors()\n",
    "\n",
    "# When checking, it should print \"No behavior attached\":\n",
    "agent.check_behaviors() # This will print \"No behavior attached\"\n",
    "\n",
    "\n",
    "# Write just below this line the code that attaches the slow_down behavior\n",
    "\n",
    "\n",
    "agent.check_behaviors() # This will print \"Behavior \"slow_down\" is attached and NOT STARTED\"\n",
    "\n",
    "\n",
    "# Write just below this line the code that starts the slow_down behavior\n",
    "\n",
    "\n",
    "agent.check_behaviors() # This will print \"Behavior \"slow_down\" is attached and STARTED\"\n",
    "\n",
    "\n",
    "# Write just below this line the code that stops the slow_down behavior\n",
    "\n",
    "\n",
    "agent.check_behaviors() # This will print \"Behavior \"slow_down\" is attached and NOT STARTED\"\n",
    "\n",
    "\n",
    "# Write just below this line the code that detaches the slow_down behavior\n",
    "\n",
    "\n",
    "agent.check_behaviors() # This will print \"No behavior attached\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the method we have just describe to define, attach, start, stop and detach a behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, detach all the behaviors that might still be attached to the agent\n",
    "# (it is a good practice to do it each time you want to define a new behavior, or modify an existing one):\n",
    "agent.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a behavior where the agent progressively slows down when it approaches an obstacle:\n",
    "def slow_down(agent):\n",
    "    # Step (1): read the sensor values\n",
    "    left, right = agent.prox_activations()\n",
    "    \n",
    "    # Step (2): do some computation\n",
    "    sum_of_proxs = left + right\n",
    "    wheel_activation = 2 - sum_of_proxs\n",
    "    \n",
    "    # Step (3): return the motor activations\n",
    "    return wheel_activation, wheel_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach this behavior to the agent, specifying the frequency (in Hz) at which it will be executed\n",
    "agent.attach_behavior(slow_down, freq=10)\n",
    "# Start the behavior in the simulator\n",
    "agent.start_behavior(slow_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing the code above, you should see the behavior being executed on the agent in the simulator. Then, to stop and detach the behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop_behavior(slow_down)\n",
    "agent.detach_behavior(slow_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way is to stop and detach all the behaviors running on the agent. This avoids having to specify the name of the behavior (`slown_down` in the cell above) and also stops systematically the behavior before detaching it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also want to stop the agent wheels (i.e. setting both wheel activations to 0) by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Braitenberg vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now practice a bit. Remember the Braitenberg Vehicle examples we have seen in [this slide](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0). Those vehicles are very similar to the agent agent in the simulator. \n",
    "- It is equipped with two sensors that are activated according to the proximity of a source. With the agent, each proximeter sensor returns a value between 0 and 1 that is inversely proportional to the distance from the closest obstacle it perceives (the closer the obstacle, the highest to proximeter activation).\n",
    "- It is equipped with two motors allowing the agent to move. With the agent, we can set the activation of each wheel independently with a value between 0 and 1 (where 1 means maximum speed). \n",
    "- A behavior links sensor activations to motor activations. In the Braitenberg vehicles, this is achieved through connections that are either excitatory (the activity of the sensor increases the activity of the motor it is connected to) or inhibitory (the activity of the sensor decreases the activity of the motor it is connected to). In the agent, we have seen above that we can define a behavior as a function that (1) read the sensor activities (2) perform some computation and (3) use the result of that computation to set the wheel speed. \n",
    "\n",
    "Therefore, we can implement in the agent the various types of vehicle behaviors shown in the slide, where defining excitatory and inhibitory connections will be done through Step (2) above (*perform some computation*). We have actually already done it with the `slow_down` behavior we have defined above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Define verbally the `slow_down` behavior in term of inhibitory and excitatory connections (do it by double clicking on the next cell). Your answer must look like this (where `TO_FILL` is either the word \"excitatory\" or \"inhibitory\"):\n",
    "- The activity of the left sensor is connected to the left wheel through a TO_FILL connection.\n",
    "- The activity of the left sensor is connected to the right wheel through a TO_FILL connection.\n",
    "- The activity of the right sensor is connected to the left wheel through a TO_FILL connection.\n",
    "- The activity of the right sensor is connected to the right wheel through a TO_FILL connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click on this cell and replace this text by your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to define the `fear` behavior illustrated in [the slide](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0) using the method we have seen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fear(agent):\n",
    "    left, right = agent.prox_activations()\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty easy, isn't it? As illustrated in the slide, the `fear` behavior simply consists in the left sensor exciting the left wheel, and the right sensor exciting the right wheel. Therefore, the simplest way of programming this behavior is to directly map the left and right sensor activations to the left and right wheel speed, respectively. This is what is done in the function definition just above.\n",
    "\n",
    "Let's now analyze the properties of this `fear` behavior in more detail. Place the E-Puck in an open area in the V-REP scene, attach and start the `fear` behavior by executing the cell below, and observe how the agent behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()  # Just in case a behavior is still attached\n",
    "\n",
    "agent.attach_behavior(fear, freq=10)\n",
    "agent.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Use the cell below to answer the following questions.\n",
    "1. What happens when the activity of both sensors is null? (i.e. no obstacle is detected.) Why?\n",
    "2. How does the agent react when it detects an obstacle? (e.g. a pillar.) Why?\n",
    "3. How does the agent reacts when it approaches a corner?  Why?\n",
    "4. How does the agent reacts when it approaches perpendicularly to a wall?  Why?\n",
    "4. Imagine a small animal equipped with such a behavior in the wild. What would be its evolutionary advantages and drawbacks? (could it escape from a predator? could it collect food? Could it hide itself?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click on this cell and replace this text by your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before programming the next behavior, let's first reduce the maximum speed of the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent.max_speed = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Program the `aggression` behavior illustrated in [the slide](https://docs.google.com/presentation/d/1s6ibk_ACiJb9CERJ_8L_b4KFu9d04ZG_htUbb_YSYT4/edit#slide=id.g31e1b425a3_0_0), which consists of crossed excitatory connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggression(agent):\n",
    "    # write your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing the behavior you have defined in the cell just above, first detach the previous one and immobilize the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.detach_all_behaviors()\n",
    "agent.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then attach the `aggression` behavior and start it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.attach_behavior(aggression, freq=10)\n",
    "agent.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Use the cell below to answer the following questions.\n",
    "3. How does the agent reacts when it approaches a wall?  Why?\n",
    "2. How does the agent react when close to a moveable object (the kind of trash bins in the scene) Why?\n",
    "4. Imagine an animal equipped with such a behavior in the wild. What would be its evolutionary advantages and drawbacks? (could it escape from a predator? could it catch preys? Could it hide itself? Could it move things?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double click on this cell and replace this text by your answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this practical session. You can now close the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
