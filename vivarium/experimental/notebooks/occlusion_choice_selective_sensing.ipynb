{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick tutorial to explain how to create a environment with braitenberg vehicles equiped with selective sensors (still a draft so comments of the notebook won't be complete yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as lg\n",
    "\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "from typing import Tuple\n",
    "\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import vmap, jit\n",
    "from jax import random, ops, lax\n",
    "\n",
    "from flax import struct\n",
    "from jax_md.rigid_body import RigidBody\n",
    "from jax_md import simulate \n",
    "from jax_md import space, rigid_body, partition, quantity\n",
    "\n",
    "from vivarium.experimental.environments.utils import normal, distance \n",
    "from vivarium.experimental.environments.base_env import BaseState, BaseEnv\n",
    "from vivarium.experimental.environments.physics_engine import total_collision_energy, friction_force, dynamics_fn\n",
    "from vivarium.experimental.environments.braitenberg.simple import relative_position, proximity_map, sensor_fn, sensor\n",
    "from vivarium.experimental.environments.braitenberg.simple import Behaviors, behavior_to_params, linear_behavior\n",
    "from vivarium.experimental.environments.braitenberg.simple import lr_2_fwd_rot, fwd_rot_2_lr, motor_command\n",
    "from vivarium.experimental.environments.braitenberg.simple import braintenberg_force_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_params = {\n",
    "    Behaviors.FEAR.value: jnp.array(\n",
    "        [[1., 0., 0.], \n",
    "         [0., 1., 0.]]),\n",
    "    Behaviors.AGGRESSION.value: jnp.array(\n",
    "        [[0., 1., 0.], \n",
    "         [1., 0., 0.]]),\n",
    "    Behaviors.LOVE.value: jnp.array(\n",
    "        [[-1., 0., 1.], \n",
    "         [0., -1., 1.]]),\n",
    "    Behaviors.SHY.value: jnp.array(\n",
    "        [[0., -1., 1.], \n",
    "         [-1., 0., 1.]]),\n",
    "    Behaviors.NOOP.value: jnp.array(\n",
    "        [[0., 0., 0.], \n",
    "         [0., 0., 0.]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO : \n",
    "\n",
    "#### Agents following poison : \n",
    "\n",
    "- Test love + fear behaviors for a prey agent\n",
    "- Set proximeters to 0, 0.8 for example\n",
    "- With a type of poison for both sensors\n",
    "- Then see what are motor activations\n",
    "- Should normally be only positive for right motor in order to avoid poison \n",
    "\n",
    "#### Neighbors in the step fn : \n",
    "\n",
    "- Use a flax dataclass that stores all the neighbors representations (neighbors; agent_neighs_idx, dense_neighbors ...) and update all its values it when overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for jax.debug.breakpoint in a jupyter notebook\n",
    "class FakeStdin:\n",
    "  def readline(self):\n",
    "    return input()\n",
    "  \n",
    "# Usage : \n",
    "# jax.debug.breakpoint(backend=\"cli\", stdin=FakeStdin())\n",
    "\n",
    "# See this issue : https://github.com/google/jax/issues/11880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the classes and helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add entity sensed type as a field in entities + sensed in agents. The agents sense the \"sensed type\" of the entities. In our case, there will be preys, predators, ressources and poison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Define the constants and the classes of the environment to store its state ###\n",
    "SPACE_NDIMS = 2\n",
    "\n",
    "class EntityType(Enum):\n",
    "    AGENT = 0\n",
    "    OBJECT = 1\n",
    "\n",
    "# Already incorporates position, momentum, force, mass and velocity\n",
    "@struct.dataclass\n",
    "class EntityState(simulate.NVEState):\n",
    "    entity_type: jnp.array\n",
    "    ent_subtype: jnp.array\n",
    "    entity_idx: jnp.array\n",
    "    diameter: jnp.array\n",
    "    friction: jnp.array\n",
    "    exists: jnp.array\n",
    "    \n",
    "@struct.dataclass\n",
    "class ParticleState:\n",
    "    ent_idx: jnp.array\n",
    "    color: jnp.array\n",
    "\n",
    "@struct.dataclass\n",
    "class AgentState(ParticleState):\n",
    "    prox: jnp.array\n",
    "    motor: jnp.array\n",
    "    proximity_map_dist: jnp.array\n",
    "    proximity_map_theta: jnp.array\n",
    "    behavior: jnp.array\n",
    "    params: jnp.array\n",
    "    sensed: jnp.array\n",
    "    wheel_diameter: jnp.array\n",
    "    speed_mul: jnp.array\n",
    "    max_speed: jnp.array\n",
    "    theta_mul: jnp.array    \n",
    "    proxs_dist_max: jnp.array\n",
    "    proxs_cos_min: jnp.array\n",
    "\n",
    "@struct.dataclass\n",
    "class ObjectState(ParticleState):\n",
    "    pass\n",
    "\n",
    "@struct.dataclass\n",
    "class State(BaseState):\n",
    "    max_agents: jnp.int32\n",
    "    max_objects: jnp.int32\n",
    "    neighbor_radius: jnp.float32\n",
    "    dt: jnp.float32  # Give a more explicit name\n",
    "    collision_alpha: jnp.float32\n",
    "    collision_eps: jnp.float32\n",
    "    ent_sub_types: dict\n",
    "    entities: EntityState\n",
    "    agents: AgentState\n",
    "    objects: ObjectState    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define get_relative_displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Add doc\n",
    "def get_relative_displacement(state, agents_neighs_idx, displacement_fn):\n",
    "    body = state.entities.position\n",
    "    senders, receivers = agents_neighs_idx\n",
    "    Ra = body.center[senders]\n",
    "    Rb = body.center[receivers]\n",
    "    dR = - space.map_bond(displacement_fn)(Ra, Rb)  # Looks like it should be opposite, but don't understand why\n",
    "\n",
    "    dist, theta = proximity_map(dR, body.orientation[senders])\n",
    "    proximity_map_dist = jnp.zeros((state.agents.ent_idx.shape[0], state.entities.entity_idx.shape[0]))\n",
    "    proximity_map_dist = proximity_map_dist.at[senders, receivers].set(dist)\n",
    "    proximity_map_theta = jnp.zeros((state.agents.ent_idx.shape[0], state.entities.entity_idx.shape[0]))\n",
    "    proximity_map_theta = proximity_map_theta.at[senders, receivers].set(theta)\n",
    "    return dist, theta, proximity_map_dist, proximity_map_theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to compute motors, only use linear behaviors (don't vmap it) because we vmap the functions to compute agents proxiemters and motors at a higher level \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_behavior(proxs, params):\n",
    "    \"\"\"Compute the activation of motors with a linear combination of proximeters and parameters\n",
    "\n",
    "    :param proxs: proximeter values of an agent\n",
    "    :param params: parameters of an agent (mapping proxs to motor values)\n",
    "    :return: motor values\n",
    "    \"\"\"\n",
    "    return params.dot(jnp.hstack((proxs, 1.)))\n",
    "\n",
    "def compute_motor(proxs, params, behaviors, motors):\n",
    "    \"\"\"Compute new motor values. If behavior is manual, keep same motor values. Else, compute new values with proximeters and params.\n",
    "\n",
    "    :param proxs: proximeters of all agents\n",
    "    :param params: parameters mapping proximeters to new motor values\n",
    "    :param behaviors: array of behaviors\n",
    "    :param motors: current motor values\n",
    "    :return: new motor values\n",
    "    \"\"\"\n",
    "    manual = jnp.where(behaviors == Behaviors.MANUAL.value, 1, 0)\n",
    "    manual_mask = manual\n",
    "    linear_motor_values = linear_behavior(proxs, params)\n",
    "    motor_values = linear_motor_values * (1 - manual_mask) + motors * manual_mask\n",
    "    return motor_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 : Add functions to compute the proximeters and motors of agents with occlusion\n",
    "\n",
    "Logic for computing sensors and motors: \n",
    "\n",
    "- We get the raw proxs\n",
    "- We get the ent types of the two detected entities (left and right)\n",
    "- For each behavior, we updated the proxs according to the detected and the sensed entities (e.g sensed entities = [0, 1, 0 , 0] : only sense ent of type 1)\n",
    "- We then compute the motor values for each behavior and do a mean of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to update the two proximeter of an agent for a specific behavior \n",
    "\n",
    "- We already have the two closest proximeters in this case\n",
    "- We want to compute the value of motors associated to a behavior for these proxs\n",
    "- We can sense different type of entities \n",
    "- The two proximeters are each associated to a specific entity type\n",
    "- So if the specific entity type is detected, the proximeter value is kept \n",
    "- Else it is set to 0 so it won't have effect on the motor values \n",
    "- To do so we use a mask (mask of 1's, if an entity is detected we set it to 0 with a multiplication)\n",
    "- So if the mask is already set to 0 (i.e the ent is detected), the masked value will still be 0 even if you multiply it by 1\n",
    "- Then we update the proximeter values with a jnp.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mask(mask, e_sensed_types, ent_type):\n",
    "    cur = jnp.where(e_sensed_types == ent_type, 0, 1)\n",
    "    mask *= cur\n",
    "    return mask\n",
    "\n",
    "def keep_mask(mask, e_sensed_types, ent_type):\n",
    "    return mask\n",
    "\n",
    "def mask_proxs_occlusion(proxs, e_sensed_types, ent_sensed_arr):\n",
    "    mask = jnp.array([1, 1])\n",
    "    for ent_type, sensed in enumerate(ent_sensed_arr):\n",
    "        mask = jax.lax.cond(sensed, update_mask, keep_mask, mask, e_sensed_types, ent_type)\n",
    "    proxs = jnp.where(mask, 0, proxs)\n",
    "    return proxs\n",
    "\n",
    "# Example :\n",
    "# ent_sensed_arr = jnp.array([0, 1, 0, 0, 1])\n",
    "# proxs = jnp.array([0.8, 0.2])\n",
    "# e_sensed_types = jnp.array([4, 4]) # Modify these values to check it works\n",
    "# print(mask_proxs_occlusion(proxs, e_sensed_types, ent_sensed_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_sensed_arr = jnp.array([1, 0, 1, 0])\n",
    "proxs = jnp.array([0.8, 0.2])\n",
    "e_sensed_types = jnp.array([0, 3]) # Modify these values to check it works\n",
    "print(mask_proxs_occlusion(proxs, e_sensed_types, ent_sensed_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to compute the motor values for a specific behavior \n",
    "\n",
    "- Convert the idx of the detected entitites (associated to the values of the two proximeters) into their types\n",
    "- Mask their sensors with the function presented above \n",
    "- Compute the motors with the updated sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_behavior_motors(state, params, sensed_mask, behavior, motor, agent_proxs, sensed_ent_idx):\n",
    "    sensed_ent_types = state.entities.ent_subtype[sensed_ent_idx]\n",
    "    jax.debug.print(\"sensed_ent_idx : {x}\", x=sensed_ent_idx)\n",
    "    jax.debug.print(\"sensed_ent_types : {x}\", x=sensed_ent_types)\n",
    "\n",
    "    behavior_proxs = mask_proxs_occlusion(agent_proxs, sensed_ent_types, sensed_mask)\n",
    "    jax.debug.print(\"behavior_proxs : {x}\", x=behavior_proxs)\n",
    "    jax.debug.print(\"behavior : {x}\", x=behavior)\n",
    "\n",
    "    motors = compute_motor(behavior_proxs, params, behaviors=behavior, motors=motor)\n",
    "    return motors\n",
    "\n",
    "# See for the vectorizing idx because already in a vmaped function here\n",
    "compute_all_behavior_motors = vmap(compute_behavior_motors, in_axes=(None, 0, 0, 0, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "params = state.agents.params[idx]\n",
    "sensed_mask = state.agents.sensed[idx]\n",
    "behavior = state.agents.behavior[idx]\n",
    "motor = state.agents.motor[idx]\n",
    "print(f\"{motor = }\")\n",
    "agent_proxs = jnp.array([0.5, 0.4])\n",
    "sensed_ent_idx = jnp.array([18, 19])\n",
    "# sensed_ent_idx = jnp.array([1, 2])\n",
    "\n",
    "# print(sensed_mask)\n",
    "\n",
    "motors = compute_all_behavior_motors(state, params, sensed_mask, behavior, motor, agent_proxs, sensed_ent_idx)\n",
    "print(motors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_behavior(proxs, params):\n",
    "    \"\"\"Compute the activation of motors with a linear combination of proximeters and parameters\n",
    "\n",
    "    :param proxs: proximeter values of an agent\n",
    "    :param params: parameters of an agent (mapping proxs to motor values)\n",
    "    :return: motor values\n",
    "    \"\"\"\n",
    "    return params.dot(jnp.hstack((proxs, 1.)))\n",
    "\n",
    "def compute_motor(proxs, params, behaviors, motors):\n",
    "    \"\"\"Compute new motor values. If behavior is manual, keep same motor values. Else, compute new values with proximeters and params.\n",
    "\n",
    "    :param proxs: proximeters of all agents\n",
    "    :param params: parameters mapping proximeters to new motor values\n",
    "    :param behaviors: array of behaviors\n",
    "    :param motors: current motor values\n",
    "    :return: new motor values\n",
    "    \"\"\"\n",
    "    manual = jnp.where(behaviors == Behaviors.MANUAL.value, 1, 0)\n",
    "    manual_mask = manual\n",
    "    linear_motor_values = linear_behavior(proxs, params)\n",
    "    motor_values = linear_motor_values * (1 - manual_mask) + motors * manual_mask\n",
    "    return motor_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_proxs = jnp.array([0., 0.])\n",
    "love_params = params[0]\n",
    "print(love_params)\n",
    "love_beh = 2\n",
    "\n",
    "motors = compute_motor(behavior_proxs, love_params, behaviors=love_beh, motors=motor)\n",
    "motors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to compute the motor values each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_occlusion_proxs_motors(state, agent_idx, params, sensed, behaviors, motor, raw_proxs, ag_idx_dense_senders, ag_idx_dense_receivers):\n",
    "    behavior = jnp.expand_dims(behaviors, axis=1) \n",
    "    ent_ag_idx = ag_idx_dense_senders[agent_idx]\n",
    "    agent_raw_proxs = raw_proxs[ent_ag_idx]\n",
    "\n",
    "    agent_proxs = jnp.max(agent_raw_proxs, axis=0)\n",
    "    sensed_ent_idx = jnp.argmax(agent_raw_proxs, axis=0)\n",
    "    \n",
    "    motor_values = compute_all_behavior_motors(state, params, sensed, behavior, motor, agent_proxs, sensed_ent_idx)\n",
    "    motors = jnp.mean(motor_values, axis=0)\n",
    "\n",
    "    return agent_proxs, motors\n",
    "\n",
    "compute_all_agents_proxs_motors_occl = vmap(compute_occlusion_proxs_motors, in_axes=(None, 0, 0, 0, 0, 0, None, None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 : Add functions to compute the proximeters and motors of agents without occlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Mask sensors and don't change functions\n",
    "\n",
    "- mask_sensors: mask sensors according to sensed entity type for an agent\n",
    "- don't change: return agent raw_proxs (surely return either the masked or the same prox array according to a sensed e type)\n",
    "\n",
    "Then for each agent, we iterate on all of his behaviors. For each behavior, we iterate on each possible sensed entity type. If the entity is sensed, we keep the raw proximeters of the agent as they are currently. If it is not, we mask the proximeters of the specific (non sensed) entity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Add doc\n",
    "def mask_sensors(state, agent_raw_proxs, ent_type_id, ent_target_idx):\n",
    "    mask = jnp.where(state.entities.ent_subtype[ent_target_idx] == ent_type_id, 0, 1)\n",
    "    mask = jnp.expand_dims(mask, 1)\n",
    "    mask = jnp.broadcast_to(mask, agent_raw_proxs.shape)\n",
    "    return agent_raw_proxs * mask\n",
    "\n",
    "def dont_change(state, agent_raw_proxs, ent_type_id, ent_target_idx):\n",
    "    return agent_raw_proxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add compute_behavior_prox, compute_behavior_proxs_motors, compute_agent_proxs_motors\n",
    "\n",
    "- compute_behavior_prox: compute the proxs for one behavior (enumerate through all the sensed entities on this particular behavior)\n",
    "- compute_behavior_proxs_motors: use fn above to compute the proxs and compute the motor values according to the behavior\n",
    "- -->vmap compute_all_behavior_proxs_motors:  computes this for all the behaviors of an agent\n",
    "- compute_agent_proxs_motors: compute the proximeters and motor values of an agent for all its behaviors. Just return mean motor value\n",
    "- -->vmap compute_all_agents_proxs_motors: computes this for all agents (vmap over params, sensed and agent_raw_proxs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Add doc on all these functions\n",
    "\n",
    "\n",
    "# TODO : Use a fori_loop on this later\n",
    "def compute_behavior_prox(state, agent_raw_proxs, ent_target_idx, sensed_entities):\n",
    "    for ent_type_id, sensed in enumerate(sensed_entities):\n",
    "        # need the lax.cond because you don't want to change the proxs if you perceive the entity\n",
    "        # but you want to mask the raw proxs if you don't detect it\n",
    "        agent_raw_proxs = lax.cond(sensed, dont_change, mask_sensors, state, agent_raw_proxs, ent_type_id, ent_target_idx)\n",
    "    proxs = jnp.max(agent_raw_proxs, axis=0)\n",
    "    return proxs\n",
    "\n",
    "def compute_behavior_proxs_motors(state, params, sensed, behavior, motor, agent_raw_proxs, ent_target_idx):\n",
    "    behavior_prox = compute_behavior_prox(state, agent_raw_proxs, ent_target_idx, sensed)\n",
    "    behavior_motors = compute_motor(behavior_prox, params, behavior, motor)\n",
    "    return behavior_prox, behavior_motors\n",
    "\n",
    "# vmap on params, sensed and behavior (parallelize on all agents behaviors at once, but not motorrs because are the same)\n",
    "compute_all_behavior_proxs_motors = vmap(compute_behavior_proxs_motors, in_axes=(None, 0, 0, 0, None, None, None))\n",
    "\n",
    "def compute_agent_proxs_motors(state, agent_idx, params, sensed, behavior, motor, raw_proxs, ag_idx_dense_senders, ag_idx_dense_receivers):\n",
    "    behavior = jnp.expand_dims(behavior, axis=1)\n",
    "    ent_ag_idx = ag_idx_dense_senders[agent_idx]\n",
    "    ent_target_idx = ag_idx_dense_receivers[agent_idx]\n",
    "    agent_raw_proxs = raw_proxs[ent_ag_idx]\n",
    "\n",
    "    # vmap on params, sensed, behaviors and motorss (vmap on all agents)\n",
    "    agent_proxs, agent_motors = compute_all_behavior_proxs_motors(state, params, sensed, behavior, motor, agent_raw_proxs, ent_target_idx)\n",
    "    mean_agent_motors = jnp.mean(agent_motors, axis=0)\n",
    "\n",
    "    return agent_proxs, mean_agent_motors\n",
    "\n",
    "compute_all_agents_proxs_motors = vmap(compute_agent_proxs_motors, in_axes=(None, 0, 0, 0, 0, 0, None, None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add classical braitenberg force fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the main environment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--- 4 Define the environment class with its different functions (step ...) ---#\n",
    "class SelectiveSensorsEnv(BaseEnv):\n",
    "    def __init__(self, state, occlusion=True, seed=42):\n",
    "        self.seed = seed\n",
    "        # TODO CLean that\n",
    "        self.occlusion = occlusion\n",
    "        self.update_agent_prox_motor_function()\n",
    "        self.init_key = random.PRNGKey(seed)\n",
    "        self.displacement, self.shift = space.periodic(state.box_size)\n",
    "        self.init_fn, self.apply_physics = dynamics_fn(self.displacement, self.shift, braintenberg_force_fn)\n",
    "        self.neighbor_fn = partition.neighbor_list(\n",
    "            self.displacement, \n",
    "            state.box_size,\n",
    "            r_cutoff=state.neighbor_radius,\n",
    "            dr_threshold=10.,\n",
    "            capacity_multiplier=1.5,\n",
    "            format=partition.Sparse\n",
    "        )\n",
    "\n",
    "        self.neighbors = self.allocate_neighbors(state)\n",
    "        # self.neighbors, self.agents_neighs_idx = self.allocate_neighbors(state)\n",
    "\n",
    "    def distance(self, point1, point2):\n",
    "            return distance(self.displacement, point1, point2)\n",
    "    \n",
    "    # At the moment doesn't work because the _step function isn't recompiled \n",
    "    def update_agent_prox_motor_function(self):\n",
    "         if self.occlusion:\n",
    "            self.compute_all_agents_proxs_motors = compute_all_agents_proxs_motors_occl\n",
    "         else:\n",
    "            self.compute_all_agents_proxs_motors = compute_all_agents_proxs_motors\n",
    "    \n",
    "    ### Add ag_idx_dense !!! \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def _step(self, state: State, neighbors: jnp.array, agents_neighs_idx: jnp.array, ag_idx_dense: jnp.array) -> Tuple[State, jnp.array]:\n",
    "        # Differences : compute raw proxs for all agents first \n",
    "        dist, relative_theta, proximity_dist_map, proximity_dist_theta = get_relative_displacement(state, agents_neighs_idx, displacement_fn=self.displacement)\n",
    "        senders, receivers = agents_neighs_idx\n",
    "\n",
    "        dist_max = state.agents.proxs_dist_max[senders]\n",
    "        cos_min = state.agents.proxs_cos_min[senders]\n",
    "        targer_exist_mask = state.entities.exists[agents_neighs_idx[1, :]]\n",
    "        raw_proxs = sensor_fn(dist, relative_theta, dist_max, cos_min, targer_exist_mask)\n",
    "\n",
    "        # 2: Use dense idx for neighborhoods to vmap all of this\n",
    "        # TODO : Could even just pass ag_idx_dense in the fn and do this inside\n",
    "        ag_idx_dense_senders, ag_idx_dense_receivers = ag_idx_dense\n",
    "\n",
    "        agent_proxs, mean_agent_motors = self.compute_all_agents_proxs_motors(\n",
    "            state,\n",
    "            state.agents.ent_idx,\n",
    "            state.agents.params,\n",
    "            state.agents.sensed,\n",
    "            state.agents.behavior,\n",
    "            state.agents.motor,\n",
    "            raw_proxs,\n",
    "            ag_idx_dense_senders,\n",
    "            ag_idx_dense_receivers,\n",
    "        )\n",
    "\n",
    "        agents = state.agents.replace(\n",
    "            prox=agent_proxs, \n",
    "            proximity_map_dist=proximity_dist_map, \n",
    "            proximity_map_theta=proximity_dist_theta,\n",
    "            motor=mean_agent_motors\n",
    "        )\n",
    "\n",
    "        # Last block unchanged\n",
    "        state = state.replace(agents=agents)\n",
    "        entities = self.apply_physics(state, neighbors)\n",
    "        state = state.replace(time=state.time+1, entities=entities)\n",
    "        neighbors = neighbors.update(state.entities.position.center)\n",
    "\n",
    "        return state, neighbors\n",
    "    \n",
    "    def step(self, state: State) -> State:\n",
    "        if state.entities.momentum is None:\n",
    "             state = self.init_fn(state, self.init_key)\n",
    "             \n",
    "        current_state = state\n",
    "        state, neighbors = self._step(current_state, self.neighbors, self.agents_neighs_idx, self.agents_idx_dense)\n",
    "\n",
    "        if self.neighbors.did_buffer_overflow:\n",
    "            # reallocate neighbors and run the simulation from current_state\n",
    "            lg.warning(f'NEIGHBORS BUFFER OVERFLOW at step {state.time}: rebuilding neighbors')\n",
    "            neighbors = self.allocate_neighbors(state)\n",
    "            assert not neighbors.did_buffer_overflow\n",
    "\n",
    "        self.neighbors = neighbors\n",
    "        return state\n",
    "        \n",
    "    def allocate_neighbors(self, state, position=None):\n",
    "        position = state.entities.position.center if position is None else position\n",
    "        neighbors = self.neighbor_fn.allocate(position)\n",
    "\n",
    "        # Also update the neighbor idx of agents (not the cleanest to attribute it to with self here)\n",
    "        ag_idx = state.entities.entity_type[neighbors.idx[0]] == EntityType.AGENT.value\n",
    "        self.agents_neighs_idx = neighbors.idx[:, ag_idx]\n",
    "        # Give the idx of the agents in sparse representation, under a dense representation (used to get the raw proxs in compute motors function)\n",
    "        agents_idx_dense_senders = jnp.array([jnp.argwhere(jnp.equal(self.agents_neighs_idx[0, :], idx)).flatten() for idx in jnp.arange(state.max_agents)]) \n",
    "        # Note: jnp.argwhere(jnp.equal(self.agents_neighs_idx[0, :], idx)).flatten() ~ jnp.where(agents_idx[0, :] == idx)\n",
    "        # Give the idx of the agent neighbors in dense representation\n",
    "        agents_idx_dense_receivers = self.agents_neighs_idx[1, :][agents_idx_dense_senders]\n",
    "        self.agents_idx_dense = agents_idx_dense_senders, agents_idx_dense_receivers\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n_dims = 2\n",
    "box_size = 100\n",
    "diameter = 5.0\n",
    "friction = 0.1\n",
    "mass_center = 1.0\n",
    "mass_orientation = 0.125\n",
    "neighbor_radius = 100.0\n",
    "collision_alpha = 0.5\n",
    "collision_eps = 0.1\n",
    "dt = 0.1\n",
    "wheel_diameter = 2.0\n",
    "speed_mul = 1.0\n",
    "max_speed = 10.0\n",
    "theta_mul = 1.0\n",
    "prox_dist_max = 40.0\n",
    "prox_cos_min = 0.0\n",
    "existing_agents = None\n",
    "existing_objects = None\n",
    "\n",
    "# Define number of agents and objects\n",
    "n_preys = 5\n",
    "n_preds = 5\n",
    "n_ress = 5\n",
    "n_pois = 5\n",
    "max_agents = n_preys + n_preds\n",
    "max_objects = n_ress + n_pois\n",
    "\n",
    "\n",
    "ent_sub_types_list = [['PREY', 5], ['PRED', 5], ['RESSOURCE', 5], ['POISON', 5]]\n",
    "# Not the cleanest but associates a sub type to an idx and to a number of elements of this subtype\n",
    "# Could use nested dicts here but not rly rly important\n",
    "# ex: Prey idx = 0, n_preys = 5\n",
    "ent_sub_types = {t[0]: [i, t[1]] for i, t in enumerate(ent_sub_types_list)}\n",
    "print(ent_sub_types)\n",
    "\n",
    "key = random.PRNGKey(seed)\n",
    "key, key_agents_pos, key_objects_pos, key_orientations = random.split(key, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ent_sub_types.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities\n",
    "\n",
    "Compared to simple Braitenberg env, just need to add a field ent_subtypes. So just need to add 1 more field in the init fn that either takes a list or ints as arguments (in case of ints care because we need to differentiate objects and agents ... --> But in classical case all the agents sense any entity the same, so lets not care abt it) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_entities(\n",
    "    max_agents=max_agents,\n",
    "    max_objects=max_objects,\n",
    "    n_dims=n_dims,\n",
    "    box_size=box_size,\n",
    "    existing_agents=None,\n",
    "    existing_objects=None,\n",
    "    mass_center=mass_center,\n",
    "    mass_orientation=mass_orientation,\n",
    "    diameter=diameter,\n",
    "    friction=friction,\n",
    "    # TODO\n",
    "    ent_sub_types=ent_sub_types,\n",
    "    key_agents_pos=random.PRNGKey(seed),\n",
    "    key_objects_pos=random.PRNGKey(seed+1),\n",
    "    key_orientations=random.PRNGKey(seed+2)\n",
    "):\n",
    "\n",
    "    existing_agents = max_agents if not existing_agents else existing_agents\n",
    "    existing_objects = max_objects if not existing_objects else existing_objects\n",
    "\n",
    "    n_entities = max_agents + max_objects # we store the entities data in jax arrays of length max_agents + max_objects \n",
    "    # Assign random positions to each entity in the environment\n",
    "    agents_positions = random.uniform(key_agents_pos, (max_agents, n_dims)) * box_size\n",
    "    objects_positions = random.uniform(key_objects_pos, (max_objects, n_dims)) * box_size\n",
    "    positions = jnp.concatenate((agents_positions, objects_positions))\n",
    "    # Assign random orientations between 0 and 2*pi to each entity\n",
    "    orientations = random.uniform(key_orientations, (n_entities,)) * 2 * jnp.pi\n",
    "    # Assign types to the entities\n",
    "    agents_entities = jnp.full(max_agents, EntityType.AGENT.value)\n",
    "    object_entities = jnp.full(max_objects, EntityType.OBJECT.value)\n",
    "    entity_types = jnp.concatenate((agents_entities, object_entities), dtype=int)\n",
    "    # Define arrays with existing entities\n",
    "    exists_agents = jnp.concatenate((jnp.ones((existing_agents)), jnp.zeros((max_agents - existing_agents))))\n",
    "    exists_objects = jnp.concatenate((jnp.ones((existing_objects)), jnp.zeros((max_objects - existing_objects))))\n",
    "    exists = jnp.concatenate((exists_agents, exists_objects), dtype=int)\n",
    "\n",
    "    # Works because dictionaries are ordered in Python\n",
    "    ent_subtypes = np.zeros(n_entities)\n",
    "    cur_idx = 0\n",
    "    for subtype_id, n_subtype in ent_sub_types.values():\n",
    "        ent_subtypes[cur_idx:cur_idx+n_subtype] = subtype_id\n",
    "        cur_idx += n_subtype\n",
    "    ent_subtypes = jnp.array(ent_subtypes, dtype=int) \n",
    "    print(ent_subtypes)\n",
    "\n",
    "    return EntityState(\n",
    "        position=RigidBody(center=positions, orientation=orientations),\n",
    "        momentum=None,\n",
    "        force=RigidBody(center=jnp.zeros((n_entities, 2)), orientation=jnp.zeros(n_entities)),\n",
    "        mass=RigidBody(center=jnp.full((n_entities, 1), mass_center), orientation=jnp.full((n_entities), mass_orientation)),\n",
    "        entity_type=entity_types,\n",
    "        ent_subtype=ent_subtypes,\n",
    "        entity_idx = jnp.array(list(range(max_agents)) + list(range(max_objects))),\n",
    "        diameter=jnp.full((n_entities), diameter),\n",
    "        friction=jnp.full((n_entities), friction),\n",
    "        exists=exists\n",
    "    )\n",
    "\n",
    "entities = init_entities(ent_sub_types=ent_sub_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "Now this section becomes rly different. Need to have several behaviors for each agent (or an array of 1 behavior at minimum). Is the better choice to create a different w different functions in the step according to if you are in selective sensing / classic braitenberg mode ? Idk, would argue the second one is cleaner and also enables to simplify init functions. \n",
    "\n",
    "Preys:\n",
    "\n",
    "- Love: other preys and ressources\n",
    "- Fear: predators and poison\n",
    "- Color: Blue\n",
    "\n",
    "Predators:\n",
    "\n",
    "- Aggression: preys\n",
    "- Fear: Poison\n",
    "- Color: Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_behavior_map(behavior, sensed_mask):\n",
    "    params = behavior_to_params(behavior)\n",
    "    sensed_mask = jnp.array([sensed_mask])\n",
    "\n",
    "    behavior_map = {\n",
    "        'behavior': behavior,\n",
    "        'params': params,\n",
    "        'sensed_mask': sensed_mask\n",
    "    }\n",
    "    return behavior_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_behaviors(behaviors_dict_list):\n",
    "    # init variables\n",
    "    n_behaviors = len(behaviors_dict_list)\n",
    "    sensed_length = behaviors_dict_list[0]['sensed_mask'].shape[1]\n",
    "\n",
    "    params = np.zeros((n_behaviors, 2, 3)) # (2, 3) = params.shape\n",
    "    sensed_mask = np.zeros((n_behaviors, sensed_length))\n",
    "    behaviors = np.zeros((n_behaviors,))\n",
    "\n",
    "    # iterate in the list of behaviors and update params and mask\n",
    "    for i in range(n_behaviors):\n",
    "        assert behaviors_dict_list[i]['sensed_mask'].shape[1] == sensed_length\n",
    "        params[i] = behaviors_dict_list[i]['params']\n",
    "        sensed_mask[i] = behaviors_dict_list[i]['sensed_mask']\n",
    "        behaviors[i] = behaviors_dict_list[i]['behavior']\n",
    "\n",
    "    stacked_behavior_map = {\n",
    "        'behaviors': behaviors,\n",
    "        'params': params,\n",
    "        'sensed_mask': sensed_mask\n",
    "    }\n",
    "\n",
    "    return stacked_behavior_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agents_params_and_sensed_arr(agents_stacked_behaviors_list):\n",
    "    n_agents = len(agents_stacked_behaviors_list)\n",
    "    params_shape = agents_stacked_behaviors_list[0]['params'].shape\n",
    "    sensed_shape = agents_stacked_behaviors_list[0]['sensed_mask'].shape\n",
    "    behaviors_shape = agents_stacked_behaviors_list[0]['behaviors'].shape\n",
    "    # Init arrays w right shapes\n",
    "    params = np.zeros((n_agents, *params_shape))\n",
    "    sensed = np.zeros((n_agents, *sensed_shape))\n",
    "    behaviors = np.zeros((n_agents, *behaviors_shape))\n",
    "\n",
    "    for i in range(n_agents):\n",
    "        assert agents_stacked_behaviors_list[i]['params'].shape == params_shape\n",
    "        assert agents_stacked_behaviors_list[i]['sensed_mask'].shape == sensed_shape\n",
    "        assert agents_stacked_behaviors_list[i]['behaviors'].shape == behaviors_shape\n",
    "        params[i] = agents_stacked_behaviors_list[i]['params']\n",
    "        sensed[i] = agents_stacked_behaviors_list[i]['sensed_mask']\n",
    "        behaviors[i] = agents_stacked_behaviors_list[i]['behaviors']\n",
    "\n",
    "    params = jnp.array(params)\n",
    "    sensed = jnp.array(sensed)\n",
    "    behaviors = jnp.array(behaviors)\n",
    "\n",
    "    return params, sensed, behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prey behavior maps\n",
    "prey_love = define_behavior_map(Behaviors.LOVE.value, [1, 0, 1, 0])\n",
    "prey_fear = define_behavior_map(Behaviors.FEAR.value, [0, 1, 0, 1])\n",
    "\n",
    "# Pred behavior maps\n",
    "pred_aggr = define_behavior_map(Behaviors.AGGRESSION.value, [1, 0, 0, 0])\n",
    "pred_fear = define_behavior_map(Behaviors.FEAR.value, [0, 0, 0, 1])\n",
    "\n",
    "# Stack the behaviors for pred and preys\n",
    "prey_behaviors_list = [prey_love, prey_fear]\n",
    "prey_behaviors = stack_behaviors(prey_behaviors_list)\n",
    "\n",
    "pred_behaviors_list = [pred_aggr, pred_fear]\n",
    "pred_behaviors = stack_behaviors(pred_behaviors_list)\n",
    "\n",
    "print(prey_behaviors)\n",
    "print(pred_behaviors)\n",
    "\n",
    "# Build a list with the stacked behaviors of all agents\n",
    "agents_stacked_behaviors_list = [prey_behaviors] * n_preys + [pred_behaviors] * n_preds\n",
    "params, sensed, behaviors = get_agents_params_and_sensed_arr(agents_stacked_behaviors_list)\n",
    "\n",
    "print(params.shape)\n",
    "print(sensed.shape)\n",
    "print(behaviors.shape)\n",
    "\n",
    "\n",
    "prey_color = jnp.array([0., 0., 1.])\n",
    "pred_color = jnp.array([1., 0., 0.])\n",
    "\n",
    "prey_color=jnp.tile(prey_color, (n_preys, 1))\n",
    "pred_color=jnp.tile(pred_color, (n_preds, 1))\n",
    "\n",
    "agent_colors = jnp.concatenate([\n",
    "    prey_color,\n",
    "    pred_color\n",
    "])\n",
    "\n",
    "agents =  AgentState(\n",
    "    # idx in the entities (ent_idx) state to map agents information in the different data structures\n",
    "    ent_idx=jnp.arange(max_agents, dtype=int), \n",
    "    prox=jnp.zeros((max_agents, 2)),\n",
    "    motor=jnp.zeros((max_agents, 2)),\n",
    "    behavior=behaviors,\n",
    "    params=params,\n",
    "    sensed=sensed,\n",
    "    wheel_diameter=jnp.full((max_agents), wheel_diameter),\n",
    "    speed_mul=jnp.full((max_agents), speed_mul),\n",
    "    max_speed=jnp.full((max_agents), max_speed),\n",
    "    theta_mul=jnp.full((max_agents), theta_mul),\n",
    "    proxs_dist_max=jnp.full((max_agents), prox_dist_max),\n",
    "    proxs_cos_min=jnp.full((max_agents), prox_cos_min),\n",
    "    proximity_map_dist=jnp.zeros((max_agents, 1)),\n",
    "    proximity_map_theta=jnp.zeros((max_agents, 1)),\n",
    "    color=jnp.tile(agent_colors, (max_agents, 1))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects\n",
    "\n",
    "Nothing to add to init functions.\n",
    "\n",
    "Ressources\n",
    "\n",
    "- Color: green\n",
    "\n",
    "Poison\n",
    "\n",
    "- Color: purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities idx of objects\n",
    "start_idx, stop_idx = max_agents, max_agents + max_objects \n",
    "objects_ent_idx = jnp.arange(start_idx, stop_idx, dtype=int)\n",
    "\n",
    "res_color = jnp.array([0., 1., 0.])\n",
    "pois_color = jnp.array([1., 0., 1.])\n",
    "\n",
    "res_color=jnp.tile(res_color, (n_preys, 1))\n",
    "pois_color=jnp.tile(pois_color, (n_preds, 1))\n",
    "\n",
    "objects_colors = jnp.concatenate([\n",
    "    res_color,\n",
    "    pois_color\n",
    "])\n",
    "\n",
    "objects =  ObjectState(\n",
    "    ent_idx=objects_ent_idx,\n",
    "    color=jnp.tile(objects_colors, (max_objects, 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state =  State(\n",
    "    time=0,\n",
    "    box_size=box_size,\n",
    "    max_agents=max_agents,\n",
    "    max_objects=max_objects,\n",
    "    neighbor_radius=neighbor_radius,\n",
    "    collision_alpha=collision_alpha,\n",
    "    collision_eps=collision_eps,\n",
    "    dt=dt,\n",
    "    entities=entities,\n",
    "    agents=agents,\n",
    "    objects=objects,\n",
    "    ent_sub_types=ent_sub_types\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.experimental.environments.braitenberg.render import render, render_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SelectiveSensorsEnv(state, occlusion=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autonomous behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10_000\n",
    "hist = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    state = env.step(state)\n",
    "    hist.append(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important remark \n",
    "\n",
    "- It seemed there was a bug bc agents preys (blue) chasing poison (purple) even though they should fear them \n",
    "- It seems like it is because they indeed don't sense them \n",
    "- So they have their proxs at 0 when detecting them\n",
    "- But it leads to have their motors at 1 !!! \n",
    "- This is because for love the motor values are (1 - left) (1 - right)\n",
    "- So even if my proxs are at 0 and I shouldn't sense this entity, it looks like so\n",
    "- So pretty weird ... \n",
    "- Idk how to fix this yet .. \n",
    "- Bc even if 1 prox is at 0 and the other 0.5\n",
    "- It will still do something bad because I never want to have my motors activated by an ent thats not sensed\n",
    "- Maybe try to add conditions or jsp quoi \n",
    "- clc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_history(hist, skip_frames=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test manual behavior for an agent\n",
    "\n",
    "Need to set all of its behaviors to manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_idx = 9\n",
    "manual_behaviors = jnp.array([Behaviors.MANUAL.value, Behaviors.MANUAL.value,])\n",
    "manual_color = jnp.array([0., 0., 0.])\n",
    "manual_motors = jnp.array([1., 1.])\n",
    "\n",
    "behaviors = state.agents.behavior.at[ag_idx].set(manual_behaviors)\n",
    "colors = state.agents.color.at[ag_idx].set(manual_color)\n",
    "motors = state.agents.motor.at[ag_idx].set(manual_motors)\n",
    "\n",
    "agents = state.agents.replace(behavior=behaviors, color=colors, motor=motors)\n",
    "state = state.replace(agents=agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5_000\n",
    "hist = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    state = env.step(state)\n",
    "    hist.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_history(hist, skip_frames=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove occlusion for agents\n",
    "\n",
    "Doesn't work yet but maybe not really important. In fact even if the function is changed the compiled _step function in the env stays the same. So I could give the compute_all_agents_proxs_motors function as an argument of the _step but I don't know if it is worth it. (Might be the case if we also accept a function for non selective sensing in this environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before: occlusion={env.occlusion}, function={env.compute_all_agents_proxs_motors}\")\n",
    "\n",
    "env.occlusion = False\n",
    "env.update_agent_prox_motor_function()\n",
    "print(f\"After: occlusion={env.occlusion}, function={env.compute_all_agents_proxs_motors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10_000\n",
    "hist = []\n",
    "for i in range(n_steps):\n",
    "    state = env.step(state)\n",
    "    hist.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_history(hist, skip_frames=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
